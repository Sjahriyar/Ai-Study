{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "! [ -e /content ] && pip install -Uqq fastbook\n",
    "import fastbook\n",
    "fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastbook import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is DeepLearning?\n",
    "Deep learning is a computer technique to extract and transform data–-with use cases ranging from human speech recognition to animal imagery classification–-by using multiple layers of neural networks. Each of these layers takes its inputs from previous layers and progressively refines them. The layers are trained by algorithms that minimize their errors and improve their accuracy. In this way, the network learns to perform a specified task.\n",
    "\n",
    "> : A PhD is definitely not required. All that matters is a deep understanding of AI & ability to implement NNs in a way that is actually useful (latter point is what’s truly hard). Don’t care if you even graduated high school."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Machine Learning?\n",
    "\n",
    "Machine learning is, like regular programming, a way to get computers to complete a specific task. But how would we use regular programming to do what we just did in the last section: recognize dogs versus cats in photos? We would have to write down for the computer the exact steps necessary to complete the task.\n",
    "\n",
    "Normally, it's easy enough for us to write down the steps to complete a task when we're writing a program. We just think about the steps we'd take if we had to do the task by hand, and then we translate them into code. For instance, we can write a function that sorts a list. In general, we'd write a function that looks something like (where *inputs* might be an unsorted list, and *results* a sorted list).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.2.1 (20241206.2353)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"289pt\" height=\"58pt\"\n",
       " viewBox=\"0.00 0.00 288.82 58.40\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 54.4)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-54.4 284.82,-54.4 284.82,4 -4,4\"/>\n",
       "<!-- program -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>program</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"174.88,-50.4 106.88,-50.4 102.88,-46.4 102.88,0 170.88,0 174.88,-4 174.88,-50.4\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"170.88,-46.4 102.88,-46.4\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"170.88,-46.4 170.88,0\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"170.88,-46.4 174.88,-50.4\"/>\n",
       "<text text-anchor=\"middle\" x=\"138.88\" y=\"-20.15\" font-family=\"Times,serif\" font-size=\"14.00\">program</text>\n",
       "</g>\n",
       "<!-- results -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>results</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"245.85\" cy=\"-25.2\" rx=\"34.97\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"245.85\" y=\"-20.15\" font-family=\"Times,serif\" font-size=\"14.00\">results</text>\n",
       "</g>\n",
       "<!-- program&#45;&gt;results -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>program&#45;&gt;results</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M175.12,-25.2C182.9,-25.2 191.24,-25.2 199.35,-25.2\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"199.07,-28.7 209.07,-25.2 199.07,-21.7 199.07,-28.7\"/>\n",
       "</g>\n",
       "<!-- inputs -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>inputs</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"33.44\" cy=\"-25.2\" rx=\"33.44\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"33.44\" y=\"-20.15\" font-family=\"Times,serif\" font-size=\"14.00\">inputs</text>\n",
       "</g>\n",
       "<!-- inputs&#45;&gt;program -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>inputs&#45;&gt;program</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M67.17,-25.2C74.81,-25.2 83.1,-25.2 91.21,-25.2\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"90.98,-28.7 100.98,-25.2 90.98,-21.7 90.98,-28.7\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x34f23cd10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_input\n",
    "#caption A traditional program\n",
    "#id basic_program\n",
    "#alt Pipeline inputs, program, results\n",
    "gv('''program[shape=box3d width=1 height=0.7]\n",
    "inputs->program->results''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But for recognizing objects in a photo that's a bit tricky; what *are* the steps we take when we recognize an object in a picture? We really don't know, since it all happens in our brain without us being consciously aware of it!\n",
    "\n",
    "Right back at the dawn of computing, in 1949, an IBM researcher named Arthur Samuel started working on a different way to get computers to complete tasks, which he called *machine learning*. In his classic 1962 essay \"Artificial Intelligence: A Frontier of Automation\", he wrote:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> : Programming a computer for such computations is, at best, a difficult task, not primarily because of any inherent complexity in the computer itself but, rather, because of the need to spell out every minute step of the process in the most exasperating detail. Computers, as any programmer will tell you, are giant morons, not giant brains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "His basic idea was this: instead of telling the computer the exact steps required to solve a problem, show it examples of the problem to solve, and let it figure out how to solve it itself. This turned out to be very effective: by 1961 his checkers-playing program had learned so much that it beat the Connecticut state champion! Here's how he described his idea (from the same essay as above):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> : Suppose we arrange for some automatic means of testing the effectiveness of any current weight assignment in terms of actual performance and provide a mechanism for altering the weight assignment so as to maximize the performance. We need not go into the details of such a procedure to see that it could be made entirely automatic and to see that a machine so programmed would \"learn\" from its experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of powerful concepts embedded in this short statement: \n",
    "\n",
    "- The idea of a \"weight assignment\" \n",
    "- The fact that every weight assignment has some \"actual performance\"\n",
    "- The requirement that there be an \"automatic means\" of testing that performance,  \n",
    "- The need for a \"mechanism\" (i.e., another automatic process) for improving the performance by changing the weight assignments\n",
    "\n",
    "Let us take these concepts one by one, in order to understand how they fit together in practice. First, we need to understand what Samuel means by a *weight assignment*.\n",
    "\n",
    "Weights are just variables, and a weight assignment is a particular choice of values for those variables. The program's inputs are values that it processes in order to produce its results—for instance, taking image pixels as inputs, and returning the classification \"dog\" as a result. The program's weight assignments are other values that define how the program will operate.\n",
    "\n",
    "Since they will affect the program they are in a sense another kind of input, so we will update our basic picture in <<basic_program>> and replace it with <<weight_assignment>> in order to take this into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"296pt\" height=\"98pt\"\n",
       " viewBox=\"0.00 0.00 296.29 98.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 94)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-94 292.29,-94 292.29,4 -4,4\"/>\n",
       "<!-- model -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>model</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"184.69,-70 116.69,-70 112.69,-66 112.69,-20 180.69,-20 184.69,-24 184.69,-70\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"180.69,-66 112.69,-66 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"180.69,-66 180.69,-20 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"180.69,-66 184.69,-70 \"/>\n",
       "<text text-anchor=\"middle\" x=\"148.69\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\">model</text>\n",
       "</g>\n",
       "<!-- results -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>results</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"254.49\" cy=\"-45\" rx=\"33.6\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"254.49\" y=\"-41.3\" font-family=\"Times,serif\" font-size=\"14.00\">results</text>\n",
       "</g>\n",
       "<!-- model&#45;&gt;results -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>model&#45;&gt;results</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M184.83,-45C193.03,-45 201.85,-45 210.35,-45\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"210.49,-48.5 220.49,-45 210.49,-41.5 210.49,-48.5\"/>\n",
       "</g>\n",
       "<!-- inputs -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>inputs</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"38.35\" cy=\"-72\" rx=\"32.49\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"38.35\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\">inputs</text>\n",
       "</g>\n",
       "<!-- inputs&#45;&gt;model -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>inputs&#45;&gt;model</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M68.38,-64.76C78.85,-62.15 90.94,-59.14 102.46,-56.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"103.54,-59.61 112.39,-53.8 101.84,-52.82 103.54,-59.61\"/>\n",
       "</g>\n",
       "<!-- weights -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>weights</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"38.35\" cy=\"-18\" rx=\"38.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"38.35\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">weights</text>\n",
       "</g>\n",
       "<!-- weights&#45;&gt;model -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>weights&#45;&gt;model</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M72.44,-26.25C81.96,-28.62 92.51,-31.25 102.63,-33.77\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"101.99,-37.22 112.54,-36.24 103.69,-30.43 101.99,-37.22\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7efcae0c5250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide_input\n",
    "#caption A program using weight assignment\n",
    "#id weight_assignment\n",
    "gv('''model[shape=box3d width=1 height=0.7]\n",
    "inputs->model->results; weights->model''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've changed the name of our box from *program* to *model*. This is to follow modern terminology and to reflect that the *model* is a special kind of program: it's one that can do *many different things*, depending on the *weights*. It can be implemented in many different ways. For instance, in Samuel's checkers program, different values of the weights would result in different checkers-playing strategies. \n",
    "\n",
    "(By the way, what Samuel called \"weights\" are most generally referred to as model *parameters* these days, in case you have encountered that term. The term *weights* is reserved for a particular type of model parameter.)\n",
    "\n",
    "Next, Samuel said we need an *automatic means of testing the effectiveness of any current weight assignment in terms of actual performance*. In the case of his checkers program, the \"actual performance\" of a model would be how well it plays. And you could automatically test the performance of two models by setting them to play against each other, and seeing which one usually wins.\n",
    "\n",
    "Finally, he says we need *a mechanism for altering the weight assignment so as to maximize the performance*. For instance, we could look at the difference in weights between the winning model and the losing model, and adjust the weights a little further in the winning direction.\n",
    "\n",
    "We can now see why he said that such a procedure *could be made entirely automatic and... a machine so programmed would \"learn\" from its experience*. Learning would become entirely automatic when the adjustment of the weights was also automatic—when instead of us improving a model by adjusting its weights manually, we relied on an automated mechanism that produced adjustments based on performance.\n",
    "\n",
    "<<training_loop>> shows the full picture of Samuel's idea of training a machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"483pt\" height=\"98pt\"\n",
       " viewBox=\"0.00 0.00 483.08 98.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 94)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-94 479.08,-94 479.08,4 -4,4\"/>\n",
       "<!-- model -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>model</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"185.69,-77 117.69,-77 113.69,-73 113.69,-27 181.69,-27 185.69,-31 185.69,-77\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"181.69,-73 113.69,-73 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"181.69,-73 181.69,-27 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"181.69,-73 185.69,-77 \"/>\n",
       "<text text-anchor=\"middle\" x=\"149.69\" y=\"-48.3\" font-family=\"Times,serif\" font-size=\"14.00\">model</text>\n",
       "</g>\n",
       "<!-- results -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>results</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"292.49\" cy=\"-52\" rx=\"33.6\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"292.49\" y=\"-48.3\" font-family=\"Times,serif\" font-size=\"14.00\">results</text>\n",
       "</g>\n",
       "<!-- model&#45;&gt;results -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>model&#45;&gt;results</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M185.86,-52C204.73,-52 228.14,-52 248.13,-52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"248.22,-55.5 258.22,-52 248.22,-48.5 248.22,-55.5\"/>\n",
       "</g>\n",
       "<!-- inputs -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>inputs</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"38.35\" cy=\"-72\" rx=\"32.49\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"38.35\" y=\"-68.3\" font-family=\"Times,serif\" font-size=\"14.00\">inputs</text>\n",
       "</g>\n",
       "<!-- inputs&#45;&gt;model -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>inputs&#45;&gt;model</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M69.52,-66.48C80.08,-64.55 92.18,-62.34 103.68,-60.23\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"104.39,-63.66 113.59,-58.42 103.13,-56.78 104.39,-63.66\"/>\n",
       "</g>\n",
       "<!-- performance -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>performance</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"419.18\" cy=\"-52\" rx=\"55.79\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"419.18\" y=\"-48.3\" font-family=\"Times,serif\" font-size=\"14.00\">performance</text>\n",
       "</g>\n",
       "<!-- results&#45;&gt;performance -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>results&#45;&gt;performance</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M326.58,-52C334.84,-52 344,-52 353.23,-52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"353.23,-55.5 363.23,-52 353.23,-48.5 353.23,-55.5\"/>\n",
       "</g>\n",
       "<!-- weights -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>weights</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"38.35\" cy=\"-18\" rx=\"38.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"38.35\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">weights</text>\n",
       "</g>\n",
       "<!-- weights&#45;&gt;model -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>weights&#45;&gt;model</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M70.68,-27.74C81.03,-30.96 92.75,-34.61 103.9,-38.07\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"102.92,-41.43 113.51,-41.06 105,-34.75 102.92,-41.43\"/>\n",
       "</g>\n",
       "<!-- performance&#45;&gt;weights -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>performance&#45;&gt;weights</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M380.65,-38.79C364.18,-33.57 344.49,-28.08 326.29,-25 242.8,-10.86 143.72,-12.41 86.54,-15.05\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"86.17,-11.56 76.36,-15.55 86.52,-18.55 86.17,-11.56\"/>\n",
       "<text text-anchor=\"middle\" x=\"222.19\" y=\"-19.8\" font-family=\"Times,serif\" font-size=\"14.00\">update</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7efcac812410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide_input\n",
    "#caption Training a machine learning model\n",
    "#id training_loop\n",
    "#alt The basic training loop\n",
    "gv('''ordering=in\n",
    "model[shape=box3d width=1 height=0.7]\n",
    "inputs->model->results; weights->model; results->performance\n",
    "performance->weights[constraint=false label=update]''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the distinction between the model's *results*  (e.g., the moves in a checkers game) and its *performance* (e.g., whether it wins the game, or how quickly it wins). \n",
    "\n",
    "Also note that once the model is trained—that is, once we've chosen our final, best, favorite weight assignment—then we can think of the weights as being *part of the model*, since we're not varying them any more.\n",
    "\n",
    "Therefore, actually *using* a model after it's trained looks like <<using_model>>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"285pt\" height=\"58pt\"\n",
       " viewBox=\"0.00 0.00 284.59 58.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 54)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-54 280.59,-54 280.59,4 -4,4\"/>\n",
       "<!-- model -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>model</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"172.99,-50 104.99,-50 100.99,-46 100.99,0 168.99,0 172.99,-4 172.99,-50\"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"168.99,-46 100.99,-46 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"168.99,-46 168.99,0 \"/>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"168.99,-46 172.99,-50 \"/>\n",
       "<text text-anchor=\"middle\" x=\"136.99\" y=\"-21.3\" font-family=\"Times,serif\" font-size=\"14.00\">model</text>\n",
       "</g>\n",
       "<!-- results -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>results</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"242.79\" cy=\"-25\" rx=\"33.6\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"242.79\" y=\"-21.3\" font-family=\"Times,serif\" font-size=\"14.00\">results</text>\n",
       "</g>\n",
       "<!-- model&#45;&gt;results -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>model&#45;&gt;results</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M173.14,-25C181.33,-25 190.15,-25 198.65,-25\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"198.79,-28.5 208.79,-25 198.79,-21.5 198.79,-28.5\"/>\n",
       "</g>\n",
       "<!-- inputs -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>inputs</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"32.5\" cy=\"-25\" rx=\"32.49\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"32.5\" y=\"-21.3\" font-family=\"Times,serif\" font-size=\"14.00\">inputs</text>\n",
       "</g>\n",
       "<!-- inputs&#45;&gt;model -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>inputs&#45;&gt;model</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M65.09,-25C73.11,-25 81.9,-25 90.47,-25\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"90.76,-28.5 100.76,-25 90.76,-21.5 90.76,-28.5\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7efcac8129d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide_input\n",
    "#caption Using a trained model as a program\n",
    "#id using_model\n",
    "gv('''model[shape=box3d width=1 height=0.7]\n",
    "inputs->model->results''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks identical to our original diagram in <<basic_program>>, just with the word *program* replaced with *model*. This is an important insight: *a trained model can be treated just like a regular computer program*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> jargon: Machine Learning: The training of programs developed by allowing a computer to learn from its experience, rather than through manually coding the individual steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Is a Neural Network?\n",
    "It's not too hard to imagine what the model might look like for a checkers program. There might be a range of checkers strategies encoded, and some kind of search mechanism, and then the weights could vary how strategies are selected, what parts of the board are focused on during a search, and so forth. But it's not at all obvious what the model might look like for an image recognition program, or for understanding text, or for many other interesting problems we might imagine.\n",
    "\n",
    "What we would like is some kind of function that is so flexible that it could be used to solve any given problem, just by varying its weights. Amazingly enough, this function actually exists! It's the neural network, which we already discussed. That is, if you regard a neural network as a mathematical function, it turns out to be a function which is extremely flexible depending on its weights. A mathematical proof called the *universal approximation theorem* shows that this function can solve any problem to any level of accuracy, in theory. The fact that neural networks are so flexible means that, in practice, they are often a suitable kind of model, and you can focus your effort on the process of training them—that is, of finding good weight assignments.\n",
    "\n",
    "But what about that process?  One could imagine that you might need to find a new \"mechanism\" for automatically updating weights for every problem. This would be laborious. What we'd like here as well is a completely general way to update the weights of a neural network, to make it improve at any given task. Conveniently, this also exists!\n",
    "\n",
    "This is called *stochastic gradient descent* (SGD). We'll see how neural networks and SGD work in detail in <<chapter_mnist_basics>>, as well as explaining the universal approximation theorem. For now, however, we will instead use Samuel's own words: *We need not go into the details of such a procedure to see that it could be made entirely automatic and to see that a machine so programmed would \"learn\" from its experience.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> J: Don't worry, neither SGD nor neural nets are mathematically complex. Both nearly entirely rely on addition and multiplication to do their work (but they do a _lot_ of addition and multiplication!). The main reaction we hear from students when they see the details is: \"Is that all it is?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, to recap, a neural network is a particular kind of machine learning model, which fits right in to Samuel's original conception. Neural networks are special because they are highly flexible, which means they can solve an unusually wide range of problems just by finding the right weights. This is powerful, because stochastic gradient descent provides us a way to find those weight values automatically.\n",
    "\n",
    "Having zoomed out, let's now zoom back in and revisit our image classification problem using Samuel's framework.\n",
    "\n",
    "Our inputs are the images. Our weights are the weights in the neural net. Our model is a neural net. Our results are the values that are calculated by the neural net, like \"dog\" or \"cat.\"\n",
    "\n",
    "What about the next piece, an *automatic means of testing the effectiveness of any current weight assignment in terms of actual performance*? Determining \"actual performance\" is easy enough: we can simply define our model's performance as its accuracy at predicting the correct answers.\n",
    "\n",
    "Putting this all together, and assuming that SGD is our mechanism for updating the weight assignments, we can see how our image classifier is a machine learning model, much like Samuel envisioned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a metric? \n",
    "A *metric* is a function that measures the quality of the model's predictions using the validation set, and will be printed at the end of each *epoch*. In this case, we're using `error_rate`, which is a function provided by fastai that does just what it says: tells you what percentage of images in the validation set are being classified incorrectly. Another common metric for classification is `accuracy` (which is just `1.0 - error_rate`). fastai provides many more, which will be discussed throughout this book.\n",
    "\n",
    "The concept of a metric may remind you of *loss*, but there is an important distinction. The entire purpose of loss is to define a \"measure of performance\" that the training system can use to update weights automatically. In other words, a good choice for loss is a choice that is easy for stochastic gradient descent to use. But a metric is defined for human consumption, so a good metric is one that is easy for you to understand, and that hews as closely as possible to what you want the model to do. At times, you might decide that the loss function is a suitable metric, but that is not necessarily the case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Transfer Learning?\n",
    "\n",
    "Using a pretrained model for a task different to what it was originally trained for is known as *transfer learning*. Unfortunately, because transfer learning is so under-studied, few domains have pretrained models available. For instance, there are currently few pretrained models available in medicine, making transfer learning challenging to use in that domain. In addition, it is not yet well understood how to use transfer learning for tasks such as time series analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is CNN (Convolutional Neural Network)?\n",
    "It's the current state-of-the-art approach to creating computer vision models. Their structure is inspired by how the human vision system works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Architecture?\n",
    "The architecture only describes a *template* for a mathematical function; it doesn't actually do anything until we provide values for the millions of parameters it contains. Picking an architecture isn't a very important part of the deep learning process. It's something that academics love to talk about, but in practice it is unlikely to be something you need to spend much time on. There are some standard architectures that work most of the time, and in this case we're using one called _ResNet_ that we'll be talking a lot about during the book; it is both fast and accurate for many datasets and problems. The `34` in `resnet34` refers to the number of layers in this variant of the architecture (other options are `18`, `50`, `101`, and `152`). Models using architectures with more layers take longer to train, and are more prone to overfitting (i.e. you can't train them for as many epochs before the accuracy on the validation set starts getting worse). On the other hand, when using more data, they can be quite a bit more accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Fine-Tuning (Fitting the Model)?\n",
    "This is the key to deep learning—determining how to fit the parameters of a model to get it to solve your problem. In order to fit a model, we have to provide at least one piece of information: how many times to look at each image **(known as number of *epochs*)**. The number of epochs you select will largely depend on how much time you have available, and how long you find it takes in practice to fit your model. If you select a number that is too small, you can always train for more epochs later.\n",
    "\n",
    "But why is the method called `fine_tune`, and not `fit`? fastai actually *does* have a method called `fit`, which does indeed fit a model (i.e. look at images in the training set multiple times, each time updating the parameters to make the predictions closer and closer to the target labels). But in this case, we've started with a pretrained model, and we don't want to throw away all those capabilities that it already has. There are some important tricks to adapt a pretrained model for a new dataset—a process called *fine-tuning*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> jargon: Fine-tuning: A transfer learning technique where the parameters (wights) of a pretrained model are updated by training for additional epochs using a different task to that used for pretraining."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the Head of the Model?\n",
    "The *head* of a model is the part that is newly added to be specific to the new dataset. An *epoch* is one complete pass through the dataset. After calling `fit`, the results after each epoch are printed, showing the epoch number, the training and validation set losses (the \"measure of performance\" used for training the model), and any *metrics* you've requested (error rate, in this case)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSTM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
