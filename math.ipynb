{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slope\n",
    "Slope also called **Gradient**, is just a way to measure how steep a line is.\n",
    "\n",
    "üîπ Think of a Hill\n",
    "\n",
    "Imagine you are riding a bike up a hill:\n",
    "\t‚Ä¢\tIf the hill is steep, you struggle to pedal ‚Üí High slope\n",
    "\t‚Ä¢\tIf the hill is flat, it‚Äôs easy to ride ‚Üí Low slope\n",
    "\t‚Ä¢\tIf you go downhill, you speed up ‚Üí Negative slope\n",
    "\n",
    "üîπ Math Definition\n",
    "\n",
    "Slope tells us how much y changes when x changes.\n",
    "\n",
    "üü¢ Why is Slope Important?\n",
    "\t1.\tPredicting Trends: If you plot data (like time vs. temperature), slope tells you how fast things are changing.\n",
    "\t2.\tMachine Learning: Linear regression uses slope to find the best line that fits data for predictions.\n",
    "\t3.\tPhysics: In motion, slope can show speed (velocity).\n",
    "\n",
    "Basically, slope helps us understand relationships between things!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"./images/slope.png\" width=\"350\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is y-intercept and x-intercept?\n",
    "üîπ X-Intercept (Where the Line Touches the X-Axis)\n",
    "\n",
    "The x-intercept is where the line crosses the x-axis (horizontal line).\n",
    "\t‚Ä¢\tThis happens when y = 0.\n",
    "\t‚Ä¢\tTo find it, set  y = 0  and solve for  x .\n",
    "\t‚Ä¢\tExample: If  y = 2x + 3 , set  0 = 2x + 3  ‚Üí Solve for  x .\n",
    "\t‚Ä¢\tThe x-intercept tells us when y reaches zero.\n",
    "\n",
    "üîπ Y-Intercept (Where the Line Starts on the Y-Axis)\n",
    "\n",
    "The y-intercept is where the line crosses the y-axis (vertical line).\n",
    "\t‚Ä¢\tThis happens when x = 0.\n",
    "\t‚Ä¢\tExample: In  y = 2x + 3 , the y-intercept is 3 (the line crosses the y-axis at  (0,3) ).\n",
    "\t‚Ä¢\tIt tells us the starting value of y when x is zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"./images/XYIntercepts.jpg\" width=\"350\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üü¢ Putting It All Together: Slope + X & Y Intercepts + Real-World Use\n",
    "\n",
    "At its core, these math tools (slope, intercepts) help us understand relationships between things. They‚Äôre the foundation of linear equations, which are heavily used in Machine Learning (ML) and data analysis.\n",
    "<br>\n",
    "1Ô∏è‚É£ What Do These Mean in Simple Terms?<br>\n",
    "\t1.\tSlope (Ôøº) ‚Üí How fast something is changing<br>\n",
    "\t‚Ä¢\tSteep slope = rapid change<br>\n",
    "\t‚Ä¢\tFlat slope = slow change<br>\n",
    "\t2.\tY-Intercept (Ôøº) ‚Üí The starting value when Ôøº<br>\n",
    "\t3.\tX-Intercept ‚Üí When the value of Ôøº becomes zero<br>\n",
    "\n",
    "Mathematically, a straight-line equation looks like:<br>\n",
    "Ôøº\n",
    "where:<br>\n",
    "\t‚Ä¢\tÔøº (slope) shows how fast Ôøº changes as Ôøº changes<br>\n",
    "\t‚Ä¢\tÔøº (y-intercept) tells us where the line starts on the y-axis<br>\n",
    "<br>\n",
    "2Ô∏è‚É£ How is This Used in Machine Learning?<br>\n",
    "<br>\n",
    "üîπ Predicting Future Outcomes (Linear Regression üìà)<br>\n",
    "<br>\n",
    "Imagine you want to predict house prices based on size (square meters).<br>\n",
    "\t‚Ä¢\tÔøº = house size<br>\n",
    "\t‚Ä¢\tÔøº = price<br>\n",
    "\t‚Ä¢\tSlope (Ôøº) = How much the price changes per square meter<br>\n",
    "\t‚Ä¢\tY-intercept (Ôøº) = The base price when house size = 0<br>\n",
    "<br>\n",
    "If a trained model gives you:<br>\n",
    "\n",
    "- is the slope (every extra m¬≤ adds ‚Ç¨5000)<br>\n",
    "- is the y-intercept (base price before size adds value)<br>\n",
    "- If a house is 100m¬≤, the price is 5000 √ó 100 + 50,000 = ‚Ç¨550,000<br>\n",
    "\n",
    "üëâ This is exactly how machine learning models make predictions!<br>\n",
    "\n",
    "üîπ Classifying Data in ML (Decision Boundaries üõë‚úÖ)<br>\n",
    "\n",
    "In classification tasks (e.g., spam vs. non-spam email), linear equations help draw boundaries between categories.<br>\n",
    "\n",
    "If a dataset has two features:<br>\n",
    "\t1.\tEmail length<br>\n",
    "\t2.\tNumber of suspicious words<br>\n",
    "\n",
    "We can plot emails and fit a line to separate spam from non-spam. The equation helps decide when an email crosses the boundary into spam territory.<br>\n",
    "\n",
    "3Ô∏è‚É£ How Do I Know When to Use These?<br>\n",
    "\n",
    "üîπ Use Slope & Intercepts When You Need:<br>\n",
    "‚úÖ To predict trends (e.g., sales, weather, prices)<br>\n",
    "‚úÖ To classify data (e.g., spam detection, sentiment analysis)<br>\n",
    "‚úÖ To analyze relationships (e.g., Does advertising spend increase sales?)<br>\n",
    "\n",
    "üîπ When NOT to Use Linear Models:<br>\n",
    "‚ùå If your data doesn‚Äôt follow a straight-line pattern<br>\n",
    "‚ùå If relationships are complex (e.g., deep learning, non-linear patterns)<br>\n",
    "\n",
    "4Ô∏è‚É£ Summary: Why Does This Matter in ML?<br>\n",
    "\n",
    "These concepts help machines learn patterns and make decisions:<br>\n",
    "‚úî Linear Regression ‚Üí Predicts numerical values (house prices, temperature, stock market)<br>\n",
    "‚úî Classification (Logistic Regression) ‚Üí Separates categories (spam detection, disease prediction)<br>\n",
    "‚úî Neural Networks ‚Üí Even deep learning uses slope (gradient descent) to optimize models!<br>\n",
    "\n",
    "üöÄ So understanding slope & intercepts helps you build better ML models!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenario:\n",
    "Imagine you're working with a dataset where you have two variables:\n",
    "- `x` (input): The size of the house in square feet.\n",
    "- `y` (output): The price of the house in thousands of dollars.\n",
    "\n",
    "You want to create a simple linear model to predict the price (`y`) of a house given its size (`x`). A linear model can be represented as:\n",
    "\n",
    "$$\n",
    "y = mx + b\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $m$ is the slope (how much the price changes per square foot).\n",
    "- $b$ is the y-intercept (the predicted price when the house size is 0).\n",
    "\n",
    "### Example Data:\n",
    "Let's say you have the following data points:\n",
    "\n",
    "| House Size (x, in sq ft) | Price (y, in $1000s) |\n",
    "|---------------------------|-----------------------|\n",
    "| 1000                      | 200                  |\n",
    "| 1500                      | 300                  |\n",
    "\n",
    "### Step 1: Calculate the Slope ($m$)\n",
    "The formula for the slope between two points $(x_1, y_1)$ and $(x_2, y_2)$ is:\n",
    "\n",
    "$$\n",
    "m = \\frac{y_2 - y_1}{x_2 - x_1}\n",
    "$$\n",
    "\n",
    "Using our data points:\n",
    "- $(x_1, y_1) = (1000, 200)$\n",
    "- $(x_2, y_2) = (1500, 300)$\n",
    "\n",
    "$$\n",
    "m = \\frac{300 - 200}{1500 - 1000} = \\frac{100}{500} = 0.2\n",
    "$$\n",
    "\n",
    "So, the slope $m = 0.2$. This means that for every additional square foot, the price increases by $200 (since $0.2 \\times 1000 = 200$).\n",
    "\n",
    "### Step 2: Calculate the Y-Intercept ($b$)\n",
    "The y-intercept $b$ is the value of $y$ when $x = 0$. We can use the equation of the line $y = mx + b$ and one of the data points to solve for $b$.\n",
    "\n",
    "Using the point $(1000, 200)$:\n",
    "$$\n",
    "200 = 0.2(1000) + b\n",
    "$$\n",
    "$$\n",
    "200 = 200 + b\n",
    "$$\n",
    "$$\n",
    "b = 0\n",
    "$$\n",
    "\n",
    "So, the y-intercept $b = 0$. This means that if the house size is 0 square feet, the predicted price would be $0.\n",
    "\n",
    "### Final Linear Model:\n",
    "Now we have the complete linear equation:\n",
    "$$\n",
    "y = 0.2x + 0\n",
    "$$\n",
    "\n",
    "Or simply:\n",
    "$$\n",
    "y = 0.2x\n",
    "$$\n",
    "\n",
    "### Real-World Prediction:\n",
    "If you want to predict the price of a house that is 2000 square feet:\n",
    "$$\n",
    "y = 0.2(2000) = 400\n",
    "$$\n",
    "\n",
    "This means the predicted price of a 2000 square foot house is $400,000.\n",
    "\n",
    "### Summary:\n",
    "- **Slope ($m$)**: Represents the rate of change of price with respect to house size (in this case, $0.2$ or $200 per square foot).\n",
    "- **Y-Intercept ($b$)**: Represents the base price when the house size is 0 (in this case, $0).\n",
    "\n",
    "This is a very basic example of how slope and intercept are used in a real-world machine learning scenario to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quadratic Equation\n",
    "A quadratic equation is a type of mathematical equation where the highest power of the variable (usually x) is 2. In simpler terms, it's an equation that involves a squared term $(x2)$, and no higher powers like $x^3, x^4$ etc.\n",
    "\n",
    "The general form of a quadratic equation is:\n",
    "\n",
    "$$ax2+bx+c=0$$\n",
    "\n",
    "Where:\n",
    "a, b, and c are constants (numbers),\n",
    "a != 0 (because if a=0, the equation would no longer have an $x^2$ term and wouldn't be quadratic)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a quadratic equation, the variables and constants $a$, $x$, $b$, and $c$ each have specific roles. Let's break them down in detail:\n",
    "\n",
    "#### 1. **$a$: The Coefficient of $x^2$**\n",
    "- $a$ is the coefficient of the squared term ($x^2$).\n",
    "- It determines the \"shape\" and \"direction\" of the parabola (the graph of the quadratic equation):\n",
    "  - If $a > 0$, the parabola opens **upwards** (like a smile).\n",
    "  - If $a < 0$, the parabola opens **downwards** (like a frown).\n",
    "- $a$ also affects how \"wide\" or \"narrow\" the parabola is:\n",
    "  - A larger absolute value of $a$ makes the parabola narrower.\n",
    "  - A smaller absolute value of $a$ makes the parabola wider.\n",
    "\n",
    "#### 2. **$x$: The Variable**\n",
    "- $x$ is the variable (or unknown) in the equation.\n",
    "- The goal of solving a quadratic equation is often to find the values of $x$ that satisfy the equation (i.e., the roots or solutions).\n",
    "- $x$ can take on any real number value, depending on the context of the problem.\n",
    "\n",
    "#### 3. **$b$: The Coefficient of $x$**\n",
    "- $b$ is the coefficient of the linear term ($x$).\n",
    "- It influences the slope of the parabola and helps determine the position of the vertex (the highest or lowest point of the parabola).\n",
    "- If $b = 0$, the parabola is symmetric about the $y$-axis.\n",
    "\n",
    "#### 4. **$c$: The Constant Term**\n",
    "- $c$ is the constant term in the equation.\n",
    "- It represents the $y$-intercept of the parabola, which is the point where the graph crosses the $y$-axis.\n",
    "- When $x = 0$, the value of $y$ is equal to $c$.\n",
    "\n",
    "---\n",
    "\n",
    "### Example:\n",
    "Consider the quadratic equation:\n",
    "\n",
    "$$\n",
    "2x^2 - 4x + 1 = 0\n",
    "$$\n",
    "\n",
    "Here:\n",
    "- $a = 2$: The parabola opens upwards because $a > 0$. The parabola is relatively narrow because $|a| = 2$ is not very small.\n",
    "- $b = -4$: This affects the slope of the parabola and shifts its position.\n",
    "- $c = 1$: The parabola crosses the $y$-axis at the point $(0, 1)$.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Points About Each Component:\n",
    "- **$a$:** Controls the shape and direction of the parabola.\n",
    "- **$x$:** The variable whose values we solve for.\n",
    "- **$b$:** Influences the slope and position of the parabola.\n",
    "- **$c$:** Determines the $y$-intercept of the parabola.\n",
    "\n",
    "Understanding these components helps you analyze and solve quadratic equations effectively!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quad(a,b,c,x): return a*(x**2) + b*x + c\n",
    "def make_quad(a,b,c): return partial(quad,a,b,c)\n",
    "\n",
    "f = make_quad(3,2,1)\n",
    "f(1.5)\n",
    "\n",
    "plot_function(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Metrics: Understanding MSE, MAE, and MAD\n",
    "When you build a model to predict numbers‚Äîlike house prices, temperatures, or sales‚Äîhow do you know if it‚Äôs doing a good job? That‚Äôs where _regression metrics_ come in. They‚Äôre like scorecards that tell you how close your predictions are to the real values. Let‚Äôs explore three popular ones: **Mean Absolute Error (MAE)**, **Mean Squared Error (MSE)**, and **Mean Absolute Deviation (MAD)**, and see how they work in everyday situations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Mean Squared Error (MSE)\n",
    "\n",
    "### What is MSE?\n",
    "MSE measures the average of the squared differences between predicted and actual values. By squaring the errors, it penalizes larger discrepancies more heavily than smaller ones.\n",
    "\n",
    "### Formula:\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "- $ y_i $: Actual value  \n",
    "- $ \\hat{y}_i $: Predicted value  \n",
    "- $ n $: Number of data points  \n",
    "\n",
    "### Key Characteristics:\n",
    "- **Sensitivity to Outliers**: Because MSE squares the differences, it gives more weight to large errors. This makes it ideal for scenarios where outliers are important.\n",
    "- **Units**: The result is in squared units of the data, which can make interpretation less intuitive.\n",
    "\n",
    "### Real-World Scenario: Stock Price Prediction\n",
    "Imagine you're building a model to predict stock prices. Even small errors in stock price predictions can lead to significant financial losses. Since MSE heavily penalizes large prediction errors, it ensures the model focuses on minimizing these deviations. For example, if your model predicts a stock price of $100 but the actual price is $120, the squared error will be much larger than if the actual price was $105. This makes MSE a good choice for scenarios where large errors are undesirable.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Mean Absolute Error (MAE)\n",
    "\n",
    "### What is MAE?\n",
    "MAE measures the average of the absolute differences between predicted and actual values. Unlike MSE, it treats all errors equally, regardless of their size.\n",
    "\n",
    "### Formula:\n",
    "$$\n",
    "\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^n |y_i - \\hat{y}_i|\n",
    "$$\n",
    "\n",
    "- $ y_i $: Actual value  \n",
    "- $ \\hat{y}_i $: Predicted value  \n",
    "- $ n $: Number of data points  \n",
    "\n",
    "### Key Characteristics:\n",
    "- **Robustness to Outliers**: MAE is less sensitive to outliers because it doesn't square the errors. This makes it a better choice when outliers are not critical to the analysis.\n",
    "- **Units**: The result is in the same units as the data, making it easier to interpret.\n",
    "\n",
    "### Real-World Scenario: Weather Forecasting\n",
    "Consider a weather forecasting model that predicts daily temperatures. While occasional large errors (e.g., predicting 30¬∞C instead of 40¬∞C) might occur, they are less impactful compared to the overall trend. In this case, MAE is a suitable metric because it provides a clear, interpretable measure of the average error in degrees Celsius without being overly influenced by rare extreme deviations.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Mean absolute deviation (MAD) or L1 Norm\n",
    "The mean absolute deviation of a dataset is the average distance between each data point and the mean. It gives us an idea about the variability in a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how to calculate the mean absolute deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find the Average (Mean):\n",
    "First, add up all the numbers in your list and then divide by how many numbers there are. This gives you the average or \"mean\" value.<br><br>\n",
    "- Calculate Deviations:\n",
    "For each number in your list, figure out how far it is from the average. If the number is bigger than the average, subtract the average from it. If it's smaller, subtract it from the average. This difference is the \"deviation.\"<br><br>\n",
    "- Make Deviations Positive:\n",
    "Since you want to measure how far numbers are from the mean regardless of whether they're above or below it, you take the absolute value of each deviation. That means you just look at the size of the number, ignoring if it's positive or negative.<br><br>\n",
    "- Average These Deviations:\n",
    "Now, add up all these absolute deviations and divide by the number of items in your list. This gives you the Mean Absolute Deviation.<br><br>\n",
    "Example:<br><br>\n",
    "\n",
    "Suppose you have the numbers: $2, 4, 6, 8$.<br>\n",
    "Mean: $(2 + 4 + 6 + 8) / 4 = 5$<br>\n",
    "Deviations:<br>\n",
    "\n",
    "$2 - 5 = -3 (absolute value = 3)$<br>\n",
    "$4 - 5 = -1 (absolute value = 1)$<br>\n",
    "$6 - 5 = 1$<br>\n",
    "$8 - 5 = 3$<br>\n",
    "Sum of Absolute Deviations: $3 + 1 + 1 + 3 = 8$<br>\n",
    "MAD: $8 / 4 = 2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{MAD}=\\dfrac{\\sum{\\lvert x_i-\\bar{x} \\rvert}}{n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\bar{x}$ is the mean of all the $x_i$ values.\n",
    "- $x_i$ represents each individual data point in your sample or population.\n",
    "- $|x_i - \\bar{x}|$ is the absolute deviation of each $x_i$ from the mean $\\bar{x}$.\n",
    "- $\\sum$ means sum up all these absolute deviations.\n",
    "- $n$ is the number of observations or data points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following these steps in the example below is probably the best way to learn about mean absolute deviation. <br>\n",
    "Let's find the mean absolute deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN: 16.0\n",
      "DEVIATION: [6. 1. 1. 1. 2. 5.]\n",
      "DEVIATION AVERAGE: 2.6666666666666665\n"
     ]
    }
   ],
   "source": [
    "sample = np.array([10, 15, 15, 17, 18, 21])\n",
    "mean = np.mean(sample)\n",
    "print(f\"MEAN: {mean}\")\n",
    "\n",
    "deviation = np.absolute([x for x in sample - mean])\n",
    "print(f\"DEVIATION: {deviation}\")\n",
    "\n",
    "deviations_avg = np.mean(deviation)\n",
    "print(f\"DEVIATION AVERAGE: {deviations_avg}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Comparison of Metrics\n",
    "\n",
    "| Metric   | Sensitivity to Outliers | Units          | Use Case                                      |\n",
    "|----------|--------------------------|----------------|-----------------------------------------------|\n",
    "| **MSE**  | High                     | Squared units  | When large errors are undesirable             |\n",
    "| **MAE**  | Low                      | Same as data   | When you want an interpretable average error  |\n",
    "| **MAD**  | Very low                 | Same as data   | When robustness to outliers is crucial        |\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Choosing the right regression metric depends on the specific requirements of your problem and the nature of your data. If large errors are particularly problematic, **MSE** is the way to go. For a straightforward, interpretable measure of average error, **MAE** is ideal. And when dealing with datasets that contain significant outliers, **MAD** provides a robust alternative. By understanding these metrics and their applications, you can effectively evaluate and improve the performance of your regression models in real-world scenarios.\n",
    "\n",
    "---\n",
    "\n",
    "## Example Calculation\n",
    "\n",
    "Let's consider an example with the following data:\n",
    "\n",
    "| Actual ($y$) | Predicted ($\\hat{y}$) | Difference | Squared Difference | Absolute Difference |\n",
    "|---------------|-------------------------|------------|---------------------|----------------------|\n",
    "| 10            | 12                      | -2         | 4                   | 2                    |\n",
    "| 15            | 20                      | -5         | 25                  | 5                    |\n",
    "| 20            | 18                      | 2          | 4                   | 2                    |\n",
    "\n",
    "### Calculations:\n",
    "1. **MSE**:\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{3} \\times (4 + 25 + 4) = \\frac{33}{3} = 11\n",
    "$$\n",
    "\n",
    "2. **MAE**:\n",
    "$$\n",
    "\\text{MAE} = \\frac{1}{3} \\times (2 + 5 + 2) = \\frac{9}{3} = 3\n",
    "$$\n",
    "\n",
    "3. **MAD**:\n",
    "$$\n",
    "\\text{Absolute Differences} = [2, 5, 2]\n",
    "$$\n",
    "$$\n",
    "\\text{MAD} = \\text{median}([2, 5, 2]) = 2\n",
    "$$\n",
    "\n",
    "Thus:\n",
    "- **MSE = 11**\n",
    "- **MAE = 3**\n",
    "- **MAD = 2**\n",
    "\n",
    "These metrics provide different insights into model performance, and the choice depends on the specific needs of your application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSTM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
