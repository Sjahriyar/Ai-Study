{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent (SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD is a simple yet powerful optimization algorithm used to train machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**TLDR**; <br>\n",
    " In summary, following is the process of SGD.\n",
    "\n",
    "1. **Stochastic**: Pick one data point (or a small batch) randomly from the dataset.\n",
    "2. **Gradient**: Compute the gradient of the loss with respect to each parameter (weights and biases) for that data point.\n",
    "3. **Learning Rate**: Multiply the gradient by the learning rate ($ \\eta $) to control the step size.\n",
    "4. **Update Parameters**: Adjust the parameters using:\n",
    "   $$\n",
    "   \\text{New Parameter} = \\text{Old Parameter} - \\eta \\cdot \\text{Gradient}.\n",
    "   $$\n",
    "5. **Repeat**: Go back to Step 1 and repeat the process for the next data point (or mini-batch).\n",
    "6. **Convergence**: Continue iterating until the loss stops decreasing significantly or a set number of iterations is reached.\n",
    "\n",
    "In short: **Stochastic → Gradient → Learning Rate → Update → Repeat → Converge**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Easy to understand example:**<br><br>\n",
    "You’re standing on a hilly landscape, and your goal is to find the lowest point (the valley). Each step you take moves you closer to the bottom.\n",
    "- The gradient tells you which direction is downhill.\n",
    "- The learning rate controls how big each step is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will learn each of these steps in more details. Just if you don't understand what's happening, come back and read the TLDR again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you remember the way that Arthur Samuel described machine learning, which we quoted in <<chapter_intro>>?\n",
    "\n",
    "> : Suppose we arrange for some automatic means of testing the effectiveness of any current weight assignment in terms of actual performance and provide a mechanism for altering the weight assignment so as to maximize the performance. We need not go into the details of such a procedure to see that it could be made entirely automatic and to see that a machine so programmed would \"learn\" from its experience.\n",
    "\n",
    "As we discussed, this is the key to allowing us to have a model that can get better and better—that can learn. But our pixel similarity approach does not really do this. We do not have any kind of weight assignment, or any way of improving based on testing the effectiveness of a weight assignment. In other words, we can't really improve our pixel similarity approach by modifying a set of parameters. In order to take advantage of the power of deep learning, we will first have to represent our task in the way that Arthur Samuel described it.\n",
    "\n",
    "Instead of trying to find the similarity between an image and an \"ideal image,\" we could instead look at each individual pixel and come up with a set of weights for each one, such that the highest weights are associated with those pixels most likely to be black for a particular category. For instance, pixels toward the bottom right are not very likely to be activated for a 7, so they should have a low weight for a 7, but they are likely to be activated for an 8, so they should have a high weight for an 8. This can be represented as a function and set of weight values for each possible category—for instance the probability of being the number 8:\n",
    "\n",
    "```\n",
    "def pr_eight(x,w): return (x*w).sum()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are assuming that `x` is the image, represented as a vector—in other words, with all of the rows stacked up end to end into a single long line. And we are assuming that the weights are a vector `w`. If we have this function, then we just need some way to update the weights to make them a little bit better. With such an approach, we can repeat that step a number of times, making the weights better and better, until they are as good as we can make them.\n",
    "\n",
    "We want to find the specific values for the vector `w` that causes the result of our function to be high for those images that are actually 8s, and low for those images that are not. Searching for the best vector `w` is a way to search for the best function for recognising 8s. (Because we are not yet using a deep neural network, we are limited by what our function can actually do—we are going to fix that constraint later in this chapter.) \n",
    "\n",
    "To be more specific, here are the steps that we are going to require, to turn this function into a machine learning classifier:\n",
    "\n",
    "1. *Initialize* the weights.\n",
    "1. For each image, use these weights to *predict* whether it appears to be a 3 or a 7.\n",
    "1. Based on these predictions, calculate how good the model is (its *loss*).\n",
    "1. Calculate the *gradient*, which measures for each weight, how changing that weight would change the loss\n",
    "1. *Step* (that is, change) all the weights based on that calculation.\n",
    "1. Go back to the step 2, and *repeat* the process.\n",
    "1. Iterate until you decide to *stop* the training process (for instance, because the model is good enough or you don't want to wait any longer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These seven steps, illustrated in <<gradient_descent>>, are the key to the training of all deep learning models. That deep learning turns out to rely entirely on these steps is extremely surprising and counterintuitive. It's amazing that this process can solve such complex problems. But, as you'll see, it really does!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.2.1 (20241206.2353)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"596pt\" height=\"78pt\"\n",
       " viewBox=\"0.00 0.00 596.25 78.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 74)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-74 592.25,-74 592.25,4 -4,4\"/>\n",
       "<!-- init -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>init</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">init</text>\n",
       "</g>\n",
       "<!-- predict -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>predict</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"127.51\" cy=\"-18\" rx=\"36.51\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"127.51\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">predict</text>\n",
       "</g>\n",
       "<!-- init&#45;&gt;predict -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>init&#45;&gt;predict</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M54.4,-18C62.17,-18 70.91,-18 79.55,-18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"79.26,-21.5 89.26,-18 79.26,-14.5 79.26,-21.5\"/>\n",
       "</g>\n",
       "<!-- loss -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>loss</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"228.02\" cy=\"-52\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"228.02\" y=\"-46.95\" font-family=\"Times,serif\" font-size=\"14.00\">loss</text>\n",
       "</g>\n",
       "<!-- predict&#45;&gt;loss -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>predict&#45;&gt;loss</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M158.06,-28.2C168.95,-31.96 181.36,-36.24 192.63,-40.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"191.4,-43.41 201.99,-43.36 193.68,-36.79 191.4,-43.41\"/>\n",
       "</g>\n",
       "<!-- gradient -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>gradient</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"365.13\" cy=\"-52\" rx=\"41.12\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"365.13\" y=\"-46.95\" font-family=\"Times,serif\" font-size=\"14.00\">gradient</text>\n",
       "</g>\n",
       "<!-- loss&#45;&gt;gradient -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>loss&#45;&gt;gradient</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M255.39,-52C271.56,-52 292.81,-52 312.24,-52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"312.21,-55.5 322.21,-52 312.21,-48.5 312.21,-55.5\"/>\n",
       "</g>\n",
       "<!-- step -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>step</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"470.25\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"470.25\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">step</text>\n",
       "</g>\n",
       "<!-- gradient&#45;&gt;step -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>gradient&#45;&gt;step</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M398.76,-41.24C410.3,-37.44 423.3,-33.15 434.97,-29.3\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"435.82,-32.71 444.22,-26.25 433.63,-26.06 435.82,-32.71\"/>\n",
       "</g>\n",
       "<!-- step&#45;&gt;predict -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>step&#45;&gt;predict</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M443.04,-18C385.63,-18 248.13,-18 175.42,-18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"175.84,-14.5 165.84,-18 175.84,-21.5 175.84,-14.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"289.52\" y=\"-21.2\" font-family=\"Times,serif\" font-size=\"14.00\">repeat</text>\n",
       "</g>\n",
       "<!-- stop -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>stop</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"561.25\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"561.25\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">stop</text>\n",
       "</g>\n",
       "<!-- step&#45;&gt;stop -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>step&#45;&gt;stop</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M497.47,-18C505.37,-18 514.19,-18 522.67,-18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"522.39,-21.5 532.39,-18 522.39,-14.5 522.39,-21.5\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x356009e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#id gradient_descent\n",
    "#caption The gradient descent process\n",
    "#alt Graph showing the steps for Gradient Descent\n",
    "gv('''\n",
    "init->predict->loss->gradient->step->stop\n",
    "step->predict[label=repeat]\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many different ways to do each of these seven steps.\n",
    "These are the details that make a big difference for deep learning practitioners, but it turns out that the general approach to each one generally follows some basic principles. Here are a few guidelines:\n",
    "\n",
    "- Initialize:: We initialize the parameters to random values. This may sound surprising. There are certainly other choices we could make, such as initializing them to the percentage of times that pixel is activated for that category—but since we already know that we have a routine to improve these weights, it turns out that just starting with random weights works perfectly well.\n",
    "- Loss:: This is what Samuel referred to when he spoke of *testing the effectiveness of any current weight assignment in terms of actual performance*. We need some function that will return a number that is small if the performance of the model is good (the standard approach is to treat a small loss as good, and a large loss as bad, although this is just a convention).\n",
    "- Step:: A simple way to figure out whether a weight should be increased a bit, or decreased a bit, would be just to try it: increase the weight by a small amount, and see if the loss goes up or down. Once you find the correct direction, you could then change that amount by a bit more, and a bit less, until you find an amount that works well. However, this is slow! As we will see, the magic of calculus allows us to directly figure out in which direction, and by roughly how much, to change each weight, without having to try all these small changes. The way to do this is by calculating *gradients*. This is just a performance optimization, we would get exactly the same results by using the slower manual process as well.\n",
    "- Stop:: Once we've decided how many epochs to train the model for (a few suggestions for this were given in the earlier list), we apply that decision. This is where that decision is applied. For our digit classifier, we would keep training until the accuracy of the model started getting worse, or we ran out of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The one magic step is the bit where we calculate the gradients. As we mentioned, we use calculus as a performance optimization; it allows us to more quickly calculate whether our loss will go up or down when we adjust our parameters up or down. In other words, the gradients will tell us how much we have to change each weight to make our model better.\n",
    "\n",
    "You may remember from your high school calculus class that the *derivative* of a function tells you how much a change in its parameters will change its result. If not, don't worry, lots of us forget calculus once high school is behind us! But you will have to have some intuitive understanding of what a derivative is before you continue, so if this is all very fuzzy in your head, head over to Khan Academy and complete the [lessons on basic derivatives](https://www.khanacademy.org/math/differential-calculus/dc-diff-intro). You won't have to know how to calculate them yourselves, you just have to know what a derivative is.\n",
    "\n",
    "The key point about a derivative is this: for any function, such as the quadratic function we saw in the previous section, we can calculate its derivative. The derivative is another function. It calculates the change, rather than the value. For instance, the derivative of the quadratic function at the value 3 tells us how rapidly the function changes at the value 3. More specifically, you may recall that gradient is defined as *rise/run*, that is, the change in the value of the function, divided by the change in the value of the parameter. When we know how our function will change, then we know what we need to do to make it smaller. This is the key to machine learning: having a way to change the parameters of a function to make it smaller. Calculus provides us with a computational shortcut, the derivative, which lets us directly calculate the gradients of our functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stepping With a Learning Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deciding how to change our parameters based on the values of the gradients is an important part of the deep learning process. Nearly all approaches start with the basic idea of multiplying the gradient by some small number, called the **learning rate** (LR). The learning rate is often a number between 0.001 and 0.1, although it could be anything. Often, people select a learning rate just by trying a few, and finding which results in the best model after training (we'll show you a better approach later in this book, called the **learning rate finder**). Once you've picked a learning rate, you can adjust your parameters using this simple function:\n",
    "\n",
    "```\n",
    "w -= gradient(w) * lr\n",
    "```\n",
    "\n",
    "This is known as **stepping** your parameters, using an **optimizer step**. Notice how we _subtract_ the `gradient * lr` from the parameter to update it.  This allows us to adjust the parameter in the direction of the slope by increasing the parameter when the slope is negative and decreasing the parameter when the slope is positive.  We want to adjust our parameters in the direction of the slope because our goal in deep learning is to _minimize_ the loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to look at an SGD example and see how finding a minimum can be used to train a model to fit data better.\n",
    "\n",
    "Let's start with a simple, synthetic, example model. Imagine you were measuring the speed of a roller coaster as it went over the top of a hump. It would start fast, and then get slower as it went up the hill; it would be slowest at the top, and it would then speed up again as it went downhill. You want to build a model of how the speed changes over time. If you were measuring the speed manually every second for 20 seconds, it might look something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(189., grad_fn=<SumBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def f(x): return (x**2).sum()\n",
    "\n",
    "xt = tensor([3., 4., 8., 10.]).requires_grad_()\n",
    "f(xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14., 15., 16., 17., 18., 19.])\n",
      "Speed: tensor([73.8789, 56.6959, 43.4025, 31.5738, 25.0567, 15.6109, 14.5676,  1.0600,  4.1608, -2.0337,  2.7262,  2.7004,  2.4339, 15.8165, 19.1673, 22.7341, 38.0166, 45.6997, 52.6399, 66.3772])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x352f6a1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "time = torch.arange(0,20).float()\n",
    "print(f\"Time: {time}\")\n",
    "speed = torch.randn(20)*3 + 0.75*(time-9.5)**2 + 1\n",
    "print(f\"Speed: {speed}\")\n",
    "\n",
    "plt.scatter(time, speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to distinguish clearly between the function's input (the time when we are measuring the coaster's speed) \n",
    "# and its parameters (the values that define *which* quadratic we're trying).\n",
    "def f(t, params):\n",
    "    a,b,c = params\n",
    "    return a*(t**2) + (b*t) + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step1: Initialize a random number\n",
    "params = torch.randn(3).requires_grad_()\n",
    "orig_params = params.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: tensor([ 2.5157e-02, -2.9898e-01, -1.5114e+00, -3.6122e+00, -6.6013e+00, -1.0479e+01, -1.5244e+01, -2.0899e+01, -2.7441e+01, -3.4872e+01, -4.3191e+01, -5.2398e+01, -6.2494e+01, -7.3478e+01,\n",
      "        -8.5350e+01, -9.8111e+01, -1.1176e+02, -1.2630e+02, -1.4172e+02, -1.5804e+02], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Step2: Calculate the predictions\n",
    "preds = f(time, params)\n",
    "print(f\"Predictions: {preds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAGkCAYAAADXDuRQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA89ElEQVR4nO3de1RU96H28WcidkAIcAZMQcFLxUoRUV9rJF31BIwXanRF0LSNKzWS0vYkuo65tEYDKqx6aU7NSaLHptE2oacmadVq0tpEayLYptHUaFzFJjbx7mtjVCCAyhAv+/2DdyaODDDAzDB7z/ezFsuw92/v2Ttb2Q+/q80wDEMAAAAWdVN3XwAAAEAgEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClEXYAAIClBS3sNDQ0aP78+Zo4caJ69+4tm82m0tJSr2X379+v8ePHKyYmRvHx8SooKNDRo0e9ll29erXS09Nlt9s1cOBAlZWV6fLlywG8EwAAYCZBCzvV1dVau3atmpqaNG3atFbLHTp0SDk5Ofrss8+0YcMGPf/88/rwww81duxYnTt3zqPssmXLNG/ePBUUFGj79u168MEHtXz5cs2ZMyfAdwMAAMzCFqy1sVwfY7PZdP78efXu3VtLlixpUbvzzW9+UxUVFTpy5IhiY2MlSSdOnNDgwYP18MMP64knnpDUHJ5SUlI0a9YsPffcc+7jly9frpKSEh08eFAZGRnBuDUAABDCglazY7PZZLPZ2ixz5coVbd26VdOnT3cHHUnq37+/cnNztWXLFve2bdu2yel0qrCw0OMchYWFMgxDr7zyil+vHwAAmFNIdVA+cuSIGhsblZWV1WJfVlaWDh8+LKfTKUk6ePCgJGnYsGEe5ZKTk5WYmOjeDwAAwltEd1/A9aqrqyVJDoejxT6HwyHDMFRbW6vk5GRVV1fLbrcrOjraa1nXubxpampSU1OT+/tr166ppqZGCQkJ7dY+AQCA0GAYhhoaGtSnTx/ddFPr9TchFXZc2goc1+/ztdyNVqxYobKyss5dHAAACCmnTp1SSkpKq/tDKuwkJCRIktdamZqaGtlsNsXHx7vLOp1OXbp0Sb169WpRdtSoUa1+zsKFC/XII4+4v6+rq1O/fv106tQpj75CAAAgdNXX1ys1NVU333xzm+VCKuwMGjRIUVFRqqqqarGvqqpKaWlpioyMlPR5X52qqiqNGTPGXe7MmTM6f/68MjMzW/0cu90uu93eYntsbCxhBwAAk2mvC0pIdVCOiIjQ1KlTtXnzZjU0NLi3nzx5UhUVFSooKHBvy8vLU2RkpMrLyz3OUV5eLpvN1uZcPgAAIHwEtWbn9ddf18WLF91B5v3339emTZskSZMnT1avXr1UVlam0aNHa8qUKVqwYIGcTqcWL16sxMREPfroo+5zORwOlZSUaNGiRXI4HJo4caL27t2r0tJSFRUVMccOAACQFMRJBSVpwIABOnHihNd9x44d04ABAyRJ+/bt02OPPabdu3crIiJC48aN08qVKzVo0KAWx61atUpr1qzR8ePHlZSUpMLCQhUXF6tnz54+X1d9fb3i4uJUV1dHMxYAACbh6/s7qGEnVBF2AAAwH1/f3yHVZwcAAMDfCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSCDsAAMDSIrr7Aqzq6jVDfztWo7MNTt1yc6RuHehQj5ts3X1ZAACEHcJOAGw7+LHK/vC+Pq5zurclx0VqydQM5WUmd+OVAQAQfmjG8rNtBz/WA+v3ewQdSTpT59QD6/dr28GPu+nKAAAIT4QdP7p6zVDZH96X4WWfa1vZH97X1WveSgAAgEAg7PjR347VtKjRuZ4h6eM6p/52rCZ4FwUAQJgj7PjR2YbWg05nygEAgK4j7PjRLTdH+rUcAADoOkZj+dGtAx1KjovUmTqn1347NklJcc3D0AEAsLpQmYaFsONHPW6yacnUDD2wfr9skkfgcT3aJVMzmG8HAGB5oTQNC81YfpaXmaxn7/0/SorzbKpKiovUs/f+H+bZAQBYXqhNw0LNTgDkZSZrQkZSSFTdAQAQTO1Nw2JT8zQsEzKSgvZeJOwESI+bbLptUEJ3XwYAAEHVkWlYgvWepBkLAAD4TShOw0LYAQAAfhOK07AQdgAAgN+4pmFprTeOTc2jsoI5DQthBwAA+I1rGhZJLQJPd03DQtgxqavXDO0+Uq1XD5zW7iPVLC4KAAgZoTYNC6OxTCiUJmoCAMCbUJqGxWYYRthXCdTX1ysuLk51dXWKjY3t7stpk2uiphsfmuuvDhMXAgDCha/vb5qxTKS9iZqk5omaaNICAPgiXLpE0IxlIqE4URMAwJzCqUtEyNXsVFZWymazef3as2ePR9n9+/dr/PjxiomJUXx8vAoKCnT06NFuuvLAC8WJmgAA5hNqa1cFWsjW7Cxfvly5ubke2zIzM93/fejQIeXk5GjEiBHasGGDnE6nFi9erLFjx+rAgQPq3bt3sC854EJxoiYAgLmE4tpVgRayYWfw4MHKzs5udf/ixYtlt9u1detWd6ekUaNGafDgwVq5cqWeeOKJYF1q0LgmajpT5/T6l9Sm5mF9wZyoCQBgLuHYJSLkmrF8ceXKFW3dulXTp0/36H3dv39/5ebmasuWLd14dYETihM1AQDMJRy7RIRs2JkzZ44iIiIUGxurSZMm6a233nLvO3LkiBobG5WVldXiuKysLB0+fFhOp3Ue0vVCbaImAIC5hGOXiJBrxoqLi9O8efOUk5OjhIQEHT58WD/96U+Vk5OjP/7xj5o0aZKqq6slSQ5Hy+Yah8MhwzBUW1ur5GTvL/6mpiY1NTW5v6+vrw/MzQRIKE3UBAAIrKvXDL/+vA/HLhEhF3ZGjhypkSNHur8fO3as8vPzNWzYMM2fP1+TJk1y77PZWn/Ybe1bsWKFysrK/HPB3aTHTTbLtKUCALwLxPBwV5eIB9bvl03yCDxW7RIRss1Y14uPj9eUKVP097//XY2NjUpIaH7Ju2p4rldTUyObzab4+PhWz7dw4ULV1dW5v06dOhWoSzetcJloCgBCVSCHh4dbl4iQq9lpjWtVC5vNpkGDBikqKkpVVVUtylVVVSktLU2Rka23Ndrtdtnt9oBdq9mF00RTABCKgjE8PJy6RJiiZqe2tlZbt27ViBEjFBkZqYiICE2dOlWbN29WQ0ODu9zJkydVUVGhgoKCbrxacwu3iaYAIBR1ZHh4V7i6RNw1oq9uG5RgyaAjhWDNzsyZM9WvXz999atfVWJioj766CM9+eST+uSTT1ReXu4uV1ZWptGjR2vKlClasGCBe1LBxMREPfroo913AyYWjhNNAUAoCsfh4YEUcjU7WVlZ2r59u4qKijR+/HgVFxcrIyNDb7/9tsaPH+8ul56ersrKSvXs2VMzZszQ7NmzlZaWpj//+c+WnD05GIL1mwQAoG3hODw8kEKuZmfBggVasGCBT2VHjRqlN954I8BXFD74TQIAOs7fQ8Ol8BweHkghF3bQffhNAgA6JlADOsJxeHgghVwzFrqP6zeJ1v7p2NT8j5jfJAAg8AM6wm14eCBRswM3fpMAAN8Ea0BHOA0PDyRqduCB3yQAoH3BHNARLsPDA4maHbTAbxIA0DYGdJgLYQdeBXLtrUCMXACAYGJAh7kQdhBULEUBwAoYGm4u9NlB0LAUBQCrcA3okNRiBCsDOkIPYQdB0d7IBal55AKrqwMwCwZ0mAfNWAiKjoxcCFRfIQDwNwZ0mANhB0HByAUAVhXIAR3wD8IOgiKYIxcY7QUAuB5hB0ERrJELjPYCANyIDsoIimCMXGC0FwBvrl4ztPtItV49cFq7j1QzECIMUbODoHGNXLix5iXJDzUvwVqnBoC5UNsLibCDIAvUyAVGewG4kau298Zfgly1vQwPDx+EHQRdIEYuMNoLMK9ADCqgthfXI+zAElinBjCnQDUzUduL69FBGZbgGu3V2u9nNjX/AGWdGiB0BHJQAbW9uB5hB5bAOjVAYPl7RFOgl5ChthfXoxkLlhHI0V7XY9JChJtANDUFupmJVclxPcIOLCXQ69QEYxgrYQqhJFAjmgLdzOSq7X1g/X7ZJI/rp7Y3/BB2YDmBWqcmGMNYmRMEoSSQI5qC0cwUrNpehD7CDuCDYAxjZU4QhJpANjUFq5mJVckh0UEZ8ElHfuh3RqA7awKdEcimpmAOKnDV9t41oq9uG5RA0AlDhB3AB4HuXxDoMAV0RqCbmlzNTElxnscnxUVSkwm/ohkL8EGgf+gzJwhCUTCammhmQjBQswP4INCTFjInCEJRsJqaaGZCoBF2AB8E+oc+M0AjVNHUBCuwGYYR9j0e6+vrFRcXp7q6OsXGxnb35SCEBXJouGs0luR9ThBeLOhOzP+EUOTr+5uwI8IOOiaQP/TNPs8OL0QAwUTY6QDCDkKJWQOD2YMaAPMh7HQAYQfomtYmRDRTE1ygQ6bZzw+EIl/f36Yeen7hwgWVlJRow4YNqqmpUXp6uhYsWKBvf/vb3X1pQEgKxAsxGLNLB1qga6XMfn7A7EwddgoKCrR371795Cc/0Ze//GW99NJLuueee3Tt2jXNnDmzey/u6lXpL3+RPv5YSk6Wxo6VevQwz/lhOYF6IQZ69epAC/QyHWY/P2AFph16/tprr2nHjh362c9+ph/84AfKzc3VunXrNGHCBP3oRz/S1atXu+/iNm+WBgyQcnOlmTOb/xwwoHm7Gc4vNYepykrp5Zeb/+zO/5/oMtcL8cZQ4nohbjv4cafPbeYJEQO9TIfZzw9YhWnDzpYtWxQTE6O7777bY3thYaH+9a9/6Z133umeC9u8WZoxQ/q//9dz++nTzdu7GkgCfX7XZwQ6TCFoAv1CDOaEiFevGdp9pFqvHjit3Uequ/wSD/QyHWY/P2AVpg07Bw8e1Fe+8hVFRHi2xGVlZbn3B93Vq9K8eZK3Pt+ubQ891PlakkCfXwpOmKLWKKgC/UIM1oSI2w5+rK8/sVP3rNujeb85oHvW7dHXn9gZ0rVSZj8/YBWmDTvV1dVyOFr+8HRtq66ubvXYpqYm1dfXe3z5xV/+0jIkXM8wpFOnmsuF4vmDFaaoNQqqQL8Qg7GkQKCa4QJdK2X28wNWYdqwI0k2W+s/PNvat2LFCsXFxbm/UlNT/XNBH/v4A9fXcsE+f6DDVDBqjdBCMF6IgVxSIJDNcIGulTL7+QGrMG3YSUhI8Fp7U1PTXBXvrdbHZeHChaqrq3N/nTp1yj8XlezjD3RfywX7/IEMU8GoNbr+s2gmcwvWCzEvM1lvPTZOL38vW898e4Re/l623npsXJdHAgWyGS7QtVJmPz9gFaYNO8OGDdMHH3ygK1eueGyvqqqSJGVmZrZ6rN1uV2xsrMeXX4wdK6WkSK3VKtlsUmpqc7lQPH8gw1Sga41caCZrIZgvxECsXh3oZrhAL3Rp9vMDVmDaeXby8/O1bt06/e53v9O3vvUt9/Zf/epX6tOnj8aMGRP8i+rRQ3rmmeYmGZvNsxbDFVCefrrz8+EE+vyuMHX6tPcaGJuteX9nwlSgm+Ckz5vJbrx2VzPZpk1SQUHnz29irhfijfPsJJlg4rlgNcNNyEgK2AzEZj8/YHamDTvf+MY3NGHCBD3wwAOqr69XWlqaXn75ZW3btk3r169Xj+6aYK+goPmlOm+eZ01GSkpzEOnqyzaQ5w9kmAp0E1x7zWQ2W3Mz2V13he3ki2Z9Ibqa4c7UOb3227GpObR1tRnOVSsVKGY/P2Bmpl4b68KFCyouLvZYLmLhwoUdXi4iIGtjmXkG5c2bW4ap1NSuhamrV5ubk9qrNTp2rHP3UVnZ3GTVnooKKSen4+e/HrNXB51rNJYkj8BjprW3APgfC4F2AAuBehGIF7qrmUnyXmvUlWaml19u7qPTnpdeku65p3OfIXkPgikpzTViYdpEFiys/wTgRoSdDiDsBFEgao2k4NTstNYnyB9hDT5hZW8A1yPsdABhJ8gCUWsU6GYy1/lbG1HW1fMDADrM1/e3aTsow8R69Oh6vxlv5wzkSLWODJ2nTxAAhBTTzrMDtOAaqda3r+f2lJSuNzEFY+i8xDxBABAA1OzAWgoKmoeX+7tmJNBD5yXmCQKAAKHPjuizAx/QJwgAQo6v72+asQBfuPoESS2X6wh2nyAAQIcQdgBfWaFPEIukAghD9NkBOsLsfYKYEBFAGKLPjuizgxAQ6D5BTIgIwILoswOYSSD7BLW3SKrUvEgqTVoALIqwA4SKQPUJovMzgDBHnx0glASiT1CwOj8DQIgi7AChxt/LaQSj87MLS10ACEE0YwFWN3Zsc1PYjX2BXGy25pXnx47t2uew1AWAEEXYAawu0BMiSp+P9rqxb5BrqQsCD4BuRNgBwkEgJ0RktBeAEEefHSBcBGpCxI6M9vJnXyQA8BFhBwgn/u78LDHaC0DIoxkLQNcEc7QXAHQCNTsAusY12qu9pS66OtpLYmg7gE6hZgdA1wRjtJfE0HYAnUbYAdB1gRztJTG0HUCXsOq5WPUc8JtANDO5VoRvbcRXV1eEB2Bavr6/6bMDwH8CMdqLoe0AuohmLAChjaHtALqIsAMgtDG0HUAXEXYAhLZgLWQKwLIIOwBCW7CGtl+9KlVWSi+/3Pwna3kBlkHYARD6gjG0nTl8AMti6LkYeg6YRiCGtrvm8LnxR6Gr1sgfYQpAQPj6/ibsiLADhC3m8AFMzdf3N81YAMJXR+bwAWBahB0A4Ys5fICwEFJhp7KyUjabzevXnj17WpTfv3+/xo8fr5iYGMXHx6ugoEBHjx7thisHYErM4QOEhZBcLmL58uXKzc312JaZmenx/aFDh5STk6MRI0Zow4YNcjqdWrx4scaOHasDBw6od+/ewbxkAGbkmsPn9OmWHZSlz/vsMIcPYGohGXYGDx6s7OzsNsssXrxYdrtdW7dudXdKGjVqlAYPHqyVK1fqiSeeCMalAjAz1xw+M2Y0B5vrA48/5/CRAjOSDIBPQqoZy1dXrlzR1q1bNX36dI/e1/3791dubq62bNnSjVcHwFQCPYePxDw+QDcLybAzZ84cRUREKDY2VpMmTdJbb73lsf/IkSNqbGxUVlZWi2OzsrJ0+PBhOZ3OVs/f1NSk+vp6jy8AYaygQDp+XKqokF56qfnPY8f8F3RmzGg56uv06ebtBB4g4EIq7MTFxWnevHl67rnnVFFRoWeeeUanTp1STk6Otm/f7i5XXV0tSXI4HC3O4XA4ZBiGamtrW/2cFStWKC4uzv2Vmprq/5sBYC49ekg5OdI99zT/6a+mq3nzvPcHcm176CGWpgACLGBhp62RVTd+HThwQJI0cuRIPf3005o2bZrGjh2rwsJCvf3220pOTtb8+fNbfIattYUB29m3cOFC1dXVub9OnTrV5fsFgBaYxwcICQHroDxkyBCtW7fOp7L9+vVrdV98fLymTJmin//852psbFRUVJQSEhIkfV7Dc72amhrZbDbFx8e3ek673S673e7TtQFApzGPDxASAhZ2kpOTVVRU5JdzuVa0cNXWDBo0SFFRUaqqqmpRtqqqSmlpaYqMjPTLZwNApzGPDxASQqrPjje1tbXaunWrRowY4Q4wERERmjp1qjZv3qyGhgZ32ZMnT6qiokIFLNoHIBS45vFprVndZpNSU5nHBwiwkJpnZ+bMmerXr5+++tWvKjExUR999JGefPJJffLJJyovL/coW1ZWptGjR2vKlClasGCBe1LBxMREPfroo91zAwBwvWDO4wOgVSFVs5OVlaXt27erqKhI48ePV3FxsTIyMvT2229r/PjxHmXT09NVWVmpnj17asaMGZo9e7bS0tL05z//mdmTAYSOYMzjA6BNNsPwNiYyvPi6RDwAdFqgZ1BmhmaEIV/f3yHVjAUAluWaxycQNm9uns/n+mHuKSnNTWjUHAGh1YwFAOggZmgG2kXYAQCzYoZmwCeEHQAwK2ZoBnxC2AEAs2KGZsAnhB0AMCtmaAZ8QtgBALNihmbAJ4QdADAr1wzNUsvAwwzNgBthBwDMjBmagXYxqSAAmF1BgXTXXczQDLSCsAMAVsAMzUCraMYCALSOGZphAYQdAIB3zNAMiyDsAAC8Y4ZmWARhBwDgHTM0wyIIOwAA75ihGRZB2AEAeMcMzbAIwg4AwDtmaIZFEHYAAK1jhmZYAJMKAgDaFowZmoEAIuwAANoXyBmaWYoCAUbYAQB0H5aiQBDQZwcA0D1YigJBQtgBAAQfS1EgiAg7AIDgYykKBBFhBwAQfCxFgSAi7AAAgo+lKBBEhB0AQPCxFAWCiLADAAg+lqJAEBF2AADdg6UoECRMKggA6D4sRYEgIOwAALpXIJeiAETYAQBYHWtvhb2g9NlpaGjQ/PnzNXHiRPXu3Vs2m02lpaWtlt+/f7/Gjx+vmJgYxcfHq6CgQEePHvVadvXq1UpPT5fdbtfAgQNVVlamy5cvB+hOAACmsnmzNGCAlJsrzZzZ/OeAASxFEWaCEnaqq6u1du1aNTU1adq0aW2WPXTokHJycvTZZ59pw4YNev755/Xhhx9q7NixOnfunEfZZcuWad68eSooKND27dv14IMPavny5ZozZ04A7wYAYAqsvQUXIwiuXbtmXLt2zTAMwzh37pwhyViyZInXsnfffbeRmJho1NXVubcdP37c6NmzpzF//nz3tvPnzxuRkZHG97//fY/jly1bZthsNuMf//iHz9dXV1dnSPL4TACAiV25YhgpKYbRvPBEyy+bzTBSU5vLwbR8fX8HpWbHZrPJ1trEUde5cuWKtm7dqunTpys2Nta9vX///srNzdWWLVvc27Zt2yan06nCwkKPcxQWFsowDL3yyit+u34AgMmw9hauE1Lz7Bw5ckSNjY3KyspqsS8rK0uHDx+W0+mUJB08eFCSNGzYMI9yycnJSkxMdO/3pqmpSfX19R5fAAALYe0tXCekwk51dbUkyeFwtNjncDhkGIZqa2vdZe12u6Kjo72WdZ3LmxUrViguLs79lZqa6qc7AACEBNbewnU6HHYqKyvdzVLtfR04cKBTF9VWk9f1+3wtd6OFCxeqrq7O/XXq1KlOXScAIESx9hau0+F5doYMGaJ169b5VLZfv34dOndCQoIkea2Vqampkc1mU3x8vLus0+nUpUuX1KtXrxZlR40a1ern2O122e32Dl0bAMBEXGtvzZjRHGwM4/N9rL0VdjocdpKTk1VUVBSIa9GgQYMUFRWlqqqqFvuqqqqUlpamyMhISZ/31amqqtKYMWPc5c6cOaPz588rMzMzINcIADAJ19pb8+Z5dlZOSWkOOqy9FTZCqs9ORESEpk6dqs2bN6uhocG9/eTJk6qoqFDBdX8x8/LyFBkZqfLyco9zlJeXy2aztTufDwAgDBQUSMePSxUV0ksvNf957BhBJ8wEbbmI119/XRcvXnSHmPfff1+bNm2SJE2ePNndFFVWVqbRo0drypQpWrBggZxOpxYvXqzExEQ9+uij7vM5HA6VlJRo0aJFcjgcmjhxovbu3avS0lIVFRUpIyMjWLcGAAhlrL0V9myGcX1DZuAMGDBAJ06c8Lrv2LFjGjBggPv7ffv26bHHHtPu3bsVERGhcePGaeXKlRo0aFCLY1etWqU1a9bo+PHjSkpKUmFhoYqLi9WzZ0+fr62+vl5xcXGqq6vzmN8HAIB2sfZWt/H1/R20sBPKCDsAgE7ZvNl7n6BnnqGpLAh8fX+HVJ8dAABMg7W3TIOwAwBAR1292lyj461xxLXtoYeay6HbEXYAAOgo1t4yFcIOAAAdxdpbpkLYAQCgo1h7y1QIOwAAdBRrb5kKYQcAgI5yrb0ltQw8rL0Vcgg7AAB0hmvtrb59PbenpDRvZ56dkBG05SIAALCcggLprruYQTnEEXYAAOgK1t4KeTRjAQAASyPsAAAAS6MZCwCAUMaq6l1G2AEAIFSxqrpf0IwFAEAoYlV1vyHsAAAQalhV3a8IOwAAhBpWVfcrwg4AAKGGVdX9irADAECoYVV1vyLsAAAQalhV3a8IOwAAhBpWVfcrwg4AAKGIVdX9hkkFAQAIVayq7heEHQAAQhmrqncZzVgAAMDSCDsAAMDSaMYCACBchcmK6oQdAADCURitqE4zFgAA4SbMVlQn7AAAEE7CcEV1wg4AAOEkDFdUJ+wAABBOwnBFdcIOAADhJAxXVA9K2GloaND8+fM1ceJE9e7dWzabTaWlpV7Lzp49WzabrcVXenq61/KrV69Wenq67Ha7Bg4cqLKyMl2+fDmAdwMAgImF4YrqQRl6Xl1drbVr12r48OGaNm2afvGLX7RZPioqSjt37myx7UbLli3TokWLtGDBAk2cOFF79+5VSUmJTp8+rbVr1/r1HgAAsATXiuozZjQHm+s7Klt0RfWghJ3+/furtrZWNptN58+fbzfs3HTTTcrOzm6zTHV1tZYuXarvfe97Wr58uSQpJydHly9fVklJiR566CFlZGT47R4AALAM14rq3ubZefpp5tnpDFdTlD9t27ZNTqdThYWFHtsLCwtlGIZeeeUVv34eAACWUlAgHT8uVVRIL73U/OexY5YLOlKIdlBubGxUUlKSevTooZSUFM2dO1c1NTUeZQ4ePChJGjZsmMf25ORkJSYmuvcDAIBWuFZUv+ee5j8t1HR1vZBbLmL48OEaPny4MjMzJUm7du3SU089pTfffFN79+5VTEyMpOZmLLvdrujo6BbncDgcqq6ubvUzmpqa1NTU5P6+vr7ez3cBAABCRYfDTmVlpXJzc30q+95772nEiBEdOv/DDz/s8f2ECRM0cuRIzZgxQ+vWrfPY31bTWFv7VqxYobKysg5dFwAAMKcOh50hQ4Zo3bp1PpXt169fhy/Im/z8fEVHR2vPnj3ubQkJCXI6nbp06ZJ69erlUb6mpkajRo1q9XwLFy7UI4884v6+vr5eqampfrlWAAAQWjocdpKTk1VUVBSIa2mTYRi66abPuxi5+upUVVVpzJgx7u1nzpzR+fPn3c1g3tjtdtnt9sBdLAAAaF5f6y9/aZ6NOTm5ee6ebugXFJIdlG+0adMmXbp0yWM4el5eniIjI1VeXu5Rtry8XDabTdOmTQvuRQIAgM9t3iwNGCDl5kozZzb/OWBAt6yoHrQOyq+//rouXryohoYGSdL777+vTZs2SZImT56sXr166cSJE5o5c6a+/e1vKy0tTTabTbt27dLTTz+toUOHetQoORwOlZSUaNGiRXI4HO5JBUtLS1VUVMQcOwAAdJfNm5snLbxxZfXTp5u3b9oU1CHuNsPwtsa7/w0YMEAnTpzwuu/YsWMaMGCAamtr9d3vflfvvfeePvnkE129elX9+/dXfn6+Hn/8ccXFxbU4dtWqVVqzZo2OHz+upKQkFRYWqri4WD179vT52urr6xUXF6e6ujrFxsZ2+h4BAAh7V6821+C0trK6zdY8eeGxY11u0vL1/R20sBPKCDsAAPhJZWVzk1V7Kiqa5/bpAl/f36boswMAAEzi44/9W84PCDsAAMB/kpP9W84PCDsAAMB/xo5t7pPT2uS+NpuUmtpcLkgIOwAAwH969JCeeab5v28MPK7vn346qPPtEHYAAIB/FRQ0Dy/v29dze0pK0IedSyG4ECgAALCAggLprrtCYgZlwg4AAAiMHj26PLzcH2jGAgAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlkbYAQAAlhaUsLNz507df//9Sk9PV3R0tPr27au77rpL+/bt81p+//79Gj9+vGJiYhQfH6+CggIdPXrUa9nVq1crPT1ddrtdAwcOVFlZmS5fvhzI2wEAACYSlLDz7LPP6vjx45o3b55ee+01PfPMMzp79qyys7O1c+dOj7KHDh1STk6OPvvsM23YsEHPP/+8PvzwQ40dO1bnzp3zKLts2TLNmzdPBQUF2r59ux588EEtX75cc+bMCcZtAQAAE7AZhmEE+kPOnj2rW265xWPbhQsXlJaWpszMTL3xxhvu7d/85jdVUVGhI0eOKDY2VpJ04sQJDR48WA8//LCeeOIJSVJ1dbVSUlI0a9YsPffcc+7jly9frpKSEh08eFAZGRk+XV99fb3i4uJUV1fn/kwAABDafH1/B6Vm58agI0kxMTHKyMjQqVOn3NuuXLmirVu3avr06R4X3b9/f+Xm5mrLli3ubdu2bZPT6VRhYaHHeQsLC2UYhl555RX/3wgAADCdbuugXFdXp/3792vo0KHubUeOHFFjY6OysrJalM/KytLhw4fldDolSQcPHpQkDRs2zKNccnKyEhMT3fsBAEB4i+iuD54zZ44uXryo4uJi97bq6mpJksPhaFHe4XDIMAzV1tYqOTlZ1dXVstvtio6O9lrWdS5vmpqa1NTU5P6+vr6+K7cCAABCWIdrdiorK2Wz2Xz6OnDggNdzLFq0SC+++KKeeuopjRo1qsV+m83W6udfv8/XcjdasWKF4uLi3F+pqamtlgUAAObW4ZqdIUOGaN26dT6V7devX4ttZWVlWrp0qZYtW6a5c+d67EtISJAkr7UyNTU1stlsio+Pd5d1Op26dOmSevXq1aKstxDlsnDhQj3yyCPu7+vr6wk8AABYVIfDTnJysoqKijr1YWVlZSotLVVpaakef/zxFvsHDRqkqKgoVVVVtdhXVVWltLQ0RUZGSvq8r05VVZXGjBnjLnfmzBmdP39emZmZrV6H3W6X3W7v1D0AAABzCVoH5R//+McqLS1VSUmJlixZ4rVMRESEpk6dqs2bN6uhocG9/eTJk6qoqFBBQYF7W15eniIjI1VeXu5xjvLyctlsNk2bNi0QtwEAAEwmKB2Un3zySS1evFh5eXm68847tWfPHo/92dnZ7v8uKyvT6NGjNWXKFC1YsEBOp1OLFy9WYmKiHn30UXc5h8OhkpISLVq0SA6HQxMnTtTevXtVWlqqoqIin+fYAQAA1haUSQVzcnK0a9euVvffeAn79u3TY489pt27dysiIkLjxo3TypUrNWjQoBbHrlq1SmvWrNHx48eVlJSkwsJCFRcXq2fPnj5fH5MKAgBgPr6+v4MSdkIdYQcAAPMJqRmUAQAAugthBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWBphBwAAWFpQws7OnTt1//33Kz09XdHR0erbt6/uuusu7du3r0XZ2bNny2aztfhKT0/3eu7Vq1crPT1ddrtdAwcOVFlZmS5fvhzoWwIAACYREYwPefbZZ1VdXa158+YpIyND586d05NPPqns7Gxt375d48aN8ygfFRWlnTt3tth2o2XLlmnRokVasGCBJk6cqL1796qkpESnT5/W2rVrA3pPAADAHGyGYRiB/pCzZ8/qlltu8dh24cIFpaWlKTMzU2+88YZ7++zZs7Vp0yZduHChzXNWV1crJSVFs2bN0nPPPefevnz5cpWUlOjgwYPKyMjw6frq6+sVFxenuro6xcbGduDOAABAd/H1/R2UZqwbg44kxcTEKCMjQ6dOnerUObdt2yan06nCwkKP7YWFhTIMQ6+88kqnzgsAAKyl2zoo19XVaf/+/Ro6dGiLfY2NjUpKSlKPHj2UkpKiuXPnqqamxqPMwYMHJUnDhg3z2J6cnKzExET3fgAAEN6C0mfHmzlz5ujixYsqLi722D58+HANHz5cmZmZkqRdu3bpqaee0ptvvqm9e/cqJiZGUnMzlt1uV3R0dItzOxwOVVdXt/rZTU1Nampqcn9fX1/vj1sCAAAhqMNhp7KyUrm5uT6Vfe+99zRixIgW2xctWqQXX3xRq1ev1qhRozz2Pfzwwx7fT5gwQSNHjtSMGTO0bt06j/02m63Vz25r34oVK1RWVubTPQAAAHPrcNgZMmSI1q1b51PZfv36tdhWVlampUuXatmyZZo7d65P58nPz1d0dLT27Nnj3paQkCCn06lLly6pV69eHuVrampahKjrLVy4UI888oj7+/r6eqWmpvp0LQAAwFw6HHaSk5NVVFTUqQ8rKytTaWmpSktL9fjjj3foWMMwdNNNn3cxcvXVqaqq0pgxY9zbz5w5o/Pnz7ubwbyx2+2y2+0dvHoAAGBGQeug/OMf/1ilpaUqKSnRkiVLOnTspk2bdOnSJWVnZ7u35eXlKTIyUuXl5R5ly8vLZbPZNG3aND9cNQAAMLugdFB+8skntXjxYuXl5enOO+/0aI6S5A4xJ06c0MyZM/Xtb39baWlpstls2rVrl55++mkNHTrUo0bJ4XCopKREixYtksPhcE8qWFpaqqKiIp/n2AEAANYWlEkFc3JytGvXrlb3uy6htrZW3/3ud/Xee+/pk08+0dWrV9W/f3/l5+fr8ccfV1xcXItjV61apTVr1uj48eNKSkpSYWGhiouL1bNnT5+vj0kFAQAwH1/f30EJO6GOsAMAgPmE1AzKAAAA3YWwAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALI2wAwAALC0oYefAgQO688471a9fP0VFRcnhcOi2227T+vXrvZbfv3+/xo8fr5iYGMXHx6ugoEBHjx71Wnb16tVKT0+X3W7XwIEDVVZWpsuXLwfydgAAgIkEJex8+umnSk1N1fLly/Xaa6/pf//3fzVgwAB95zvf0dKlSz3KHjp0SDk5Ofrss8+0YcMGPf/88/rwww81duxYnTt3zqPssmXLNG/ePBUUFGj79u168MEHtXz5cs2ZMycYtwUAAEzAZhiG0V0fnp2drX/96186efKke9s3v/lNVVRU6MiRI4qNjZUknThxQoMHD9bDDz+sJ554QpJUXV2tlJQUzZo1S88995z7+OXLl6ukpEQHDx5URkaGT9dRX1+vuLg41dXVuT8TAACENl/f393aZycxMVERERHu769cuaKtW7dq+vTpHhfdv39/5ebmasuWLe5t27Ztk9PpVGFhocc5CwsLZRiGXnnllYBfPwAACH0R7Rfxn2vXrunatWuqra3Vxo0btX37dv3P//yPe/+RI0fU2NiorKysFsdmZWVpx44dcjqdioyM1MGDByVJw4YN8yiXnJysxMRE935vmpqa1NTU5P6+rq5OUnNCBAAA5uB6b7fXSBXUsPPggw+6m5y+8IUvaNWqVfrBD37g3l9dXS1JcjgcLY51OBwyDEO1tbVKTk5WdXW17Ha7oqOjvZZ1ncubFStWqKysrMX21NTUDt8TAADoXg0NDYqLi2t1f4fDTmVlpXJzc30q+95772nEiBHu7x9//HEVFRXp7Nmz+sMf/qC5c+fq4sWL+uEPf+hxnM1ma/Wc1+/ztdyNFi5cqEceecT9/bVr11RTU6OEhIQ2j+uo+vp6paam6tSpU5bvCxRO9yqF1/1yr9YVTvfLvVqTYRhqaGhQnz592izX4bAzZMgQrVu3zqey/fr1a/G9a9vkyZMlNQeP++67T71791ZCQoIkea2Vqampkc1mU3x8vCQpISFBTqdTly5dUq9evVqUHTVqVKvXZbfbZbfbPba5zhsIsbGxlv8L5xJO9yqF1/1yr9YVTvfLvVpPWzU6Lh0OO8nJySoqKurUBd3o1ltv1c9//nMdPXpUvXv31qBBgxQVFaWqqqoWZauqqpSWlqbIyEhJn/fVqaqq0pgxY9zlzpw5o/PnzyszM9Mv1wgAAMytW0djVVRU6KabbtKXvvQlSVJERISmTp2qzZs3q6GhwV3u5MmTqqioUEFBgXtbXl6eIiMjVV5e7nHO8vJy2Ww2TZs2LRi3AAAAQlxQOih///vfV2xsrG699VZ98Ytf1Pnz57Vx40b99re/1Y9+9CP17t3bXbasrEyjR4/WlClTtGDBAjmdTi1evFiJiYl69NFH3eUcDodKSkq0aNEiORwOTZw4UXv37lVpaamKiop8nmMnkOx2u5YsWdKiycyKwulepfC6X+7VusLpfrnX8BaUSQVfeOEFvfDCC/rggw/06aefKiYmRsOHD1dRUZHuvffeFuX37dunxx57TLt371ZERITGjRunlStXatCgQS3Krlq1SmvWrNHx48eVlJSkwsJCFRcXq2fPnoG+LQAAYALdOoMyAABAoLHqOQAAsDTCDgAAsDTCTidcuHBBDz30kPr06aPIyEiNGDFCv/nNb3w69uzZs5o9e7YSExPVq1cv3XbbbXrzzTcDfMWds3PnTt1///1KT09XdHS0+vbtq7vuukv79u1r91jXqDhvX2fOnAnC1XdcZWVlq9e8Z8+edo8307OdPXt2q/fa3v2G+rNtaGjQ/PnzNXHiRPXu3Vs2m02lpaVey+7fv1/jx49XTEyM4uPjVVBQoKNHj/r8WW+88YZuu+029erVS4mJiZo9e7bOnj3rpztpny/3evXqVf33f/+38vLylJKSol69eukrX/mKFixYoE8//dSnz8nJyfH6vPPy8vx/U63w9bm29nc7PT3d58/q7ucq+X6/bf079uWeQ+HZBkNQl4uwioKCAu3du1c/+clP9OUvf1kvvfSS7rnnHl27dk0zZ85s9bimpibdcccd+vTTT/XMM8/olltu0Zo1a5SXl6c33nhDt99+exDvon3PPvusqqurNW/ePGVkZOjcuXN68sknlZ2dre3bt2vcuHHtnuOFF15o8Q/ONXlkqFq+fHmLWcLbm7fJbM920aJF+o//+I8W26dOnSq73a7Ro0e3e45QfbbV1dVau3athg8frmnTpukXv/iF13KHDh1STk6ORowYoQ0bNrhHfo4dO1YHDhzwGCXqza5du/SNb3xDd955p1599VWdPXtWjz32mO644w69++67QRkJ48u9NjY2qrS0VPfcc4+KioqUmJio/fv3a+nSpfrDH/6gd999V1FRUe1+1pe+9CW9+OKLHtsCORnrjXx9rpIUFRWlnTt3ttjmi1B4rpLv97t79+4W29555x099NBDys/P9+mzuvvZBoWBDvnjH/9oSDJeeuklj+0TJkww+vTpY1y5cqXVY9esWWNIMt5++233tsuXLxsZGRnGrbfeGrBr7qxPPvmkxbaGhgbji1/8onHHHXe0eewLL7xgSDL27t0bqMvzu4qKCkOSsXHjxg4fa7Zn601lZaUhySgpKWmzXKg/22vXrhnXrl0zDMMwzp07Z0gylixZ0qLc3XffbSQmJhp1dXXubcePHzd69uxpzJ8/v93PGT16tJGRkWFcvnzZve2vf/2rIcn42c9+1vUb8YEv93rlyhXj/PnzLY7duHGjIcn49a9/3e7n3H777cbQoUP9cs2d5etzve+++4zo6OhOf04oPFfD8P1+vZk9e7Zhs9mMjz76qN2yofBsg4FmrA7asmWLYmJidPfdd3tsLyws1L/+9S+98847bR47ZMgQ3Xbbbe5tERERuvfee/W3v/1Np0+fDth1d8Ytt9zSYltMTIwyMjJ06tSpbrii0GW2Z+vNL3/5S9lsNt1///3dfSld4qqGb8uVK1e0detWTZ8+3WM6/f79+ys3N1dbtmxp8/jTp09r7969+s53vqOIiM8ryL/2ta/py1/+crvH+4sv99qjRw+vNW633nqrJJnm37Iv99pVofJcpc7fb0NDgzZu3Kjbb79daWlpAbgycyLsdNDBgwf1la98xeMfgiRlZWW597d1rKuct2P/8Y9/+PFKA6Ourk779+/X0KFDfSo/ZcoU9ejRQw6HQwUFBW3+/wkVc+bMUUREhGJjYzVp0iS99dZb7R5j9mdbV1enTZs26Y477tDAgQN9OsaMz9blyJEjamxsbPWZHT58WE6ns9XjXffa2vFm+H/haubx9d/ykSNH5HA4FBERoUGDBqm4uFiNjY2BvMROa2xsVFJSknr06KGUlBTNnTtXNTU17R5nhef6m9/8RhcvXuzQsk5meradRZ+dDqqurnYvb3E9h8Ph3t/Wsa5yHT02VMyZM0cXL15UcXFxm+WSkpJUXFys7OxsxcbGqqqqSj/5yU+UnZ2tv/71rxo+fHiQrth3cXFxmjdvnnJycpSQkKDDhw/rpz/9qXJycvTHP/5RkyZNavVYsz/bl19+WY2Njfrud7/bblkzPtsbuZ5Ha8/MMAzV1tYqOTm5U8eH+vM+ffq0FixYoK9+9auaMmVKu+W//vWv61vf+pbS09PV2Nio119/Xf/1X/+lt956y73sT6gYPny4hg8f7u5nt2vXLj311FN68803tXfvXsXExLR6rNmfq9RcQxsfH6/p06f7VN5Mz7YrCDud0FbVYnvVjl05trstWrRIL774olavXt3mqvJS89pl1/fm//d//3fdeeedGjZsmBYvXqxXX3010JfbYSNHjtTIkSPd348dO1b5+fkaNmyY5s+f32bYkcz9bH/5y18qISHBpw6NZny2renqM2utTCg/75qaGk2ePFmGYei3v/2tTy+zpUuXenw/efJkDRgwQD/84Q/16quv+twRNhgefvhhj+8nTJigkSNHasaMGVq3bl2L/d6Y8blKzTXI77zzjubMmeNeNLs9Znq2XWGNyBZECQkJXtO9q4rU228E/ji2u5WVlWnp0qVatmyZ5s6d26lzDBgwQF//+td9GsYdKuLj4zVlyhT9/e9/b7Na18zP9u9//7veffdd3XvvvZ0eaWK2Z+vqw9LaM7PZbG2ORmnv+FB93rW1tZowYYJOnz6tHTt2eK2l9pVrqR8zPPP8/HxFR0e3e61mfa4uv/zlLyWpQ01Y3pjp2fqKsNNBw4YN0wcffKArV654bK+qqpLU9hDlYcOGuct19NjuVFZWptLSUpWWlurxxx/v0rkMwzBdtajx/1dUaeu3OrM+W8l/PyDN9GwHDRqkqKioVp9ZWlpam78Zu55na8eH4vOura3V+PHjdezYMe3YscNrv5TOMMsz9+Xvpxmfq8tnn32mX//61xo1apRGjBjhl3Oa5dn6wjp3EiT5+fm6cOGCfve733ls/9WvfqU+ffpozJgxbR576NAhjxFbV65c0fr16zVmzBj16dMnYNfdWT/+8Y9VWlqqkpISLVmypEvnOnbsmP76178qOzvbT1cXeLW1tdq6datGjBjR5svPjM9Wap4faP369br11lu79IPcbM82IiJCU6dO1ebNm9XQ0ODefvLkSVVUVKigoKDN4/v27atbb71V69ev19WrV93b9+zZo3/+85/tHh9srqBz9OhR/elPf/Joru2sX/3qV5Jkime+adMmXbp0qd1rNdtzvd7vf/97nT9/3qd+d+0x07P1WXeOezerCRMmGP/2b/9mrF271ti5c6fxve99z5BkrF+/3l3m/vvvN3r06GEcP37cvc3pdBpDhw41UlNTjRdffNHYsWOHkZ+fb0RERBiVlZXdcSttWrlypSHJyMvLM3bv3t3iy8Xbvd5xxx1GWVmZsWXLFuPNN980nn76aaNPnz7GzTffbFRVVXXH7bTrnnvuMR577DFj48aNRkVFhbF27VpjyJAhRkREhLFjxw53OSs8W5ff/OY3hiRj7dq1Xveb9dm+9tprxsaNG43nn3/ekGTcfffdxsaNG42NGzcaFy9eNAzDMD744AMjJibG+Pd//3fjtddeMzZv3mxkZmYaffr0Mc6ePetxvh49ehjjxo3z2FZRUWFEREQY+fn5xo4dO4wXX3zRSE1NNTIzMw2n0xky93rp0iVj9OjRhs1mM5555pkW/44PHz7c5r3++c9/NiZNmmT8/Oc/N/70pz8Zv//9740HHnjAXe7q1ashc6/Hjx83vva1rxmrVq0yXnvtNeP11183FixYYERGRhpDhw41Lly40Oa9GkboPFfD8O3vsUteXp4RFRVlfPrpp62eL5SfbaARdjqhoaHB+M///E8jKSnJ+MIXvmBkZWUZL7/8skeZ++67z5BkHDt2zGP7mTNnjFmzZhkOh8OIjIw0srOzPV6koeT22283JLX65eLtXh966CEjIyPDuPnmm42IiAijT58+xr333mv885//7IY78c2KFSuMESNGGHFxcUaPHj2M3r17G/n5+cbf/vY3j3JWeLYuEyZMMKKjo436+nqv+836bPv379/q39vr7+Xdd9817rjjDqNXr15GbGysMW3atBYvf8MwDEnG7bff3mL7n/70JyM7O9uIjIw0HA6HMWvWLK+TcQZSe/d67NixNv8d33fffR7nu/FeP/roI2Py5MlG3759DbvdbkRGRhrDhg0zli1bFvSXf3v3WlNTY+Tn5xsDBgwwoqKijC984QvG4MGDjfnz53sNAaH8XA3D97/HJ0+eNG666SZj1qxZbZ4vlJ9toNkM4/93SAAAALAg+uwAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABLI+wAAABL+380EfxpP5SjNQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_preds(preds, ax=None):\n",
    "    if ax is None: ax=plt.subplots()[1]\n",
    "    ax.scatter(time, speed)\n",
    "    ax.scatter(time, to_np(preds), color='red')\n",
    "    ax.set_ylim(-300,100)\n",
    "\n",
    "show_preds(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Loss: 10005.1826171875\n"
     ]
    }
   ],
   "source": [
    "#Step3: Measure the loss\n",
    "loss = mse(preds, speed)\n",
    "print(f\"MSE Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient: tensor([-32395.4707,  -2075.4275,   -160.6055])\n",
      "Updated Parameters: tensor([-0.4442,  0.1200,  0.0252], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the gradient\n",
    "loss.backward()\n",
    "\n",
    "# Step 4: Pick a leaning rate, For now just a small number later we will learn how to pick the right learning rate\n",
    "params.grad * 1e-5\n",
    "print(f\"Gradient: {params.grad}\")\n",
    "print(f\"Updated Parameters: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the parameters based on the calculated gradient\n",
    "lr = 1e-5\n",
    "params.data -= lr * params.grad.data\n",
    "params.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Loss: 2444.136962890625\n"
     ]
    }
   ],
   "source": [
    "# Let's see if the loss improved\n",
    "preds = f(time,params)\n",
    "print(f\"MSE Loss: {mse(preds, speed)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat the process till the loss is minimized\n",
    "def apply_step(params, prn=True):\n",
    "    preds = f(time, params)\n",
    "    loss = mse(preds, speed)\n",
    "    loss.backward()\n",
    "    params.data -= lr * params.grad.data\n",
    "    params.grad = None\n",
    "    if prn: print(loss.item())\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2444.136962890625\n",
      "1013.353515625\n",
      "742.602783203125\n",
      "691.36572265625\n",
      "681.6672973632812\n",
      "679.8292236328125\n",
      "679.4786376953125\n",
      "679.4094848632812\n",
      "679.3934326171875\n",
      "679.3876342773438\n"
     ]
    }
   ],
   "source": [
    "# Iterate by looping many improvements\n",
    "for i in range(10): apply_step(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x300 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we plot the function at every step. \n",
    "# Then we can see how the shape is approaching the best possible quadratic function for our data:\n",
    "_,axs = plt.subplots(1,4,figsize=(12,3))\n",
    "for ax in axs: show_preds(apply_step(params, False), ax)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize, at the beginning, the weights of our model can be random (training *from scratch*) or come from a pretrained model (*transfer learning*). In the first case, the output we will get from our inputs won't have anything to do with what we want, and even in the second case, it's very likely the pretrained model won't be very good at the specific task we are targeting. So the model will need to *learn* better weights.\n",
    "\n",
    "We begin by comparing the outputs the model gives us with our targets (we have labeled data, so we know what result the model should give) using a *loss function*, which returns a number that we want to make as low as possible by improving our weights. To do this, we take a few data items (such as images) from the training set and feed them to our model. We compare the corresponding targets using our loss function, and the score we get tells us how wrong our predictions were. We then change the weights a little bit to make it slightly better.\n",
    "\n",
    "To find how to change the weights to make the loss a bit better, we use calculus to calculate the *gradients*. (Actually, we let PyTorch do it for us!) Let's consider an analogy. Imagine you are lost in the mountains with your car parked at the lowest point. To find your way back to it, you might wander in a random direction, but that probably wouldn't help much. Since you know your vehicle is at the lowest point, you would be better off going downhill. By always taking a step in the direction of the steepest downward slope, you should eventually arrive at your destination. We use the magnitude of the gradient (i.e., the steepness of the slope) to tell us how big a step to take; specifically, we multiply the gradient by a number we choose called the *learning rate* to decide on the step size. We then *iterate* until we have reached the lowest point, which will be our parking lot, then we can *stop*.\n",
    "\n",
    "All of that we just saw can be transposed directly to the MNIST dataset, except for the loss function. Let's now see how we can define a good training objective. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MNIST Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### What Are We Trying to Achieve?\n",
    "\n",
    "We are preparing data for training a machine learning model. Specifically:\n",
    "1. **Input Data (`train_x`)**: These are the images of handwritten digits (3s and 7s). We need to convert these images into a format the model can understand.\n",
    "2. **Labels (`train_y`)**: These are the \"answers\" or categories for each image. For example, we label all images of `3` as `1` and all images of `7` as `0`.\n",
    "\n",
    "Once the data is prepared, we can use it to train a model that learns to distinguish between `3`s and `7`s.\n",
    "\n",
    "### Step 1: Preparing the Input Data (`train_x`)\n",
    "\n",
    "#### What Are the Images?\n",
    "- Each image is a grid of pixels (e.g., 28x28 pixels for MNIST digits).\n",
    "- In PyTorch, these images are stored as tensors (multi-dimensional arrays).\n",
    "\n",
    "#### Why Change the Shape?\n",
    "- A single image is a **matrix** (rank-2 tensor) of size `(28, 28)` (height x width).\n",
    "- To feed these images into most machine learning models, we need to \"flatten\" them into **vectors** (rank-1 tensors) of size `(784,)` (since $ 28 \\times 28 = 784 $).\n",
    "\n",
    "#### How Do We Flatten Them?\n",
    "- We use the `.view(-1, 28*28)` method:\n",
    "  - `-1`: Automatically calculates how many rows are needed based on the data.\n",
    "  - `28*28`: Flattens each image into a vector of length 784.\n",
    "\n",
    "#### Combining All Images\n",
    "- We have two groups of images: `stacked_threes` (all images of `3`) and `stacked_sevens` (all images of `7`).\n",
    "- We combine them into one big tensor using `torch.cat()`.\n",
    "\n",
    "#### Final Result:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28*28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This creates a single tensor where:\n",
    "  - Each **row** represents one flattened image (a vector of 784 pixels).\n",
    "  - The total number of rows is the total number of images (`len(threes) + len(sevens)`).\n",
    "\n",
    "### Step 2: Creating Labels (`train_y`)\n",
    "\n",
    "#### What Are Labels?\n",
    "- Labels tell the model what each image represents:\n",
    "  - `1` means the image is a `3`.\n",
    "  - `0` means the image is a `7`.\n",
    "\n",
    "#### How Do We Create Labels?\n",
    "- For all `3`s, we create a list of `1`s with the same length as the number of `3`s.\n",
    "- For all `7`s, we create a list of `0`s with the same length as the number of `7`s.\n",
    "- We concatenate these lists into one.\n",
    "\n",
    "#### Adding an Extra Dimension\n",
    "- Machine learning models often expect labels to be in a specific shape, like a column vector (rank-2 tensor with shape `(n, 1)`).\n",
    "- We use `.unsqueeze(1)` to add an extra dimension to the labels tensor.\n",
    "\n",
    "#### Final Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = tensor([1]*len(threes) + [0]*len(sevens)).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- This creates a tensor where:\n",
    "  - Each row corresponds to the label of one image.\n",
    "  - The shape is `(n, 1)`, where `n` is the total number of images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Prepare the data for PyTorch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `Dataset` in PyTorch is required to return a tuple of `(x,y)` when indexed. Python provides a `zip` function which, when combined with `list`, provides a simple way to get this functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), tensor([1]))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = list(zip(train_x,train_y))\n",
    "x,y = dataset[0]\n",
    "\n",
    "x.shape,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also we need to prepare our validation sets the same way as training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_x = torch.cat([valid_3_tens, valid_7_tens]).view(-1, 28*28)\n",
    "valid_y = tensor([1]*len(valid_3_tens) + [0]*len(valid_7_tens)).unsqueeze(1)\n",
    "valid_dset = list(zip(valid_x,valid_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset is now prepared for training, let's dive into the actual training steps.\n",
    "As you may recall: \n",
    "\n",
    "__Init->Predict->Loss->Gradient->Step->(Repeat till we have low loss)->Stop__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the training process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using **Logistic Regression** (a classification model). The purpose is to train the model to distinguish between two classes (3s and 7s) by learning a decision boundary using weights and bias. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a linear model, the prediction is calculated as: $y=w⋅x+b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In neural networks, the `w` in the equation $y=w*x+b$ is called the *weights*, and the `b` is called the *bias*. Together, the weights and bias make up the *parameters*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need an (initially random) weight for every pixel (this is the *initialize* step in our seven-step process):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize random weights for a model and prepares them for training:\n",
    "def init_params(size, std=1.0): return (torch.randn(size)*std).requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We’re creating initial weights for a model, scaled appropriately, and ensuring they’re ready for gradient-based optimization.<br><br> 1. **`torch.randn(size)`**: Creates random numbers from a normal distribution (mean = 0, std = 1) with the given shape (`size`).<br>2. **`* std`**: Scales the random numbers to control their range (e.g., smaller `std` makes weights closer to 0).<br>3. **`.requires_grad_()`**: Tells PyTorch to track these weights so their gradients can be calculated during training.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**What Is std?** <br>\n",
    "In short, std is to adjust the initial scale of the weights by making them larger or smaller at the start of training. This helps ensure the weights are in a good range for effective learning, but it doesn’t directly depend on the loss function.<br><br>\n",
    "std stands for standard deviation , which controls the spread or scale of the random numbers. <br><br>\n",
    "By multiplying the random numbers by std, we adjust their range. For example: <br><br>\n",
    "If std = 1.0, the random numbers stay as-is (standard normal distribution). <br>\n",
    "If std = 0.01, the random numbers are scaled down to be much smaller."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create weights with size (28*28, 1) because:\n",
    "- Each image is flattened into a vector of 784 pixels (features),\n",
    "- We need one weight for each pixel to compute a weighted sum,\n",
    "- The model produces a single output (e.g., a prediction for binary classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5595],\n",
       "        [ 0.0144],\n",
       "        [ 0.7486],\n",
       "        [ 0.0624],\n",
       "        [ 0.3489]], grad_fn=<SliceBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights = init_params((28*28,1))\n",
    "weights[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `weights*pixels` won't be flexible enough—it is always equal to 0 when the pixels are equal to 0 (i.e., its *intercept* is 0). You might remember from high school math that the formula for a line is `y=w*x+b`; we still need the `b`. We'll initialize it to a random number too:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This bias adds flexibility to the model by allowing it to shift predictions up or down, ensuring it can fit data even when inputs are zero. Like weights, the bias is updated during training to minimize the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.6389], requires_grad=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bias = init_params(1)\n",
    "bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now calculate a prediction for one image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.6355], grad_fn=<AddBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "one_image = train_x[0]\n",
    "weights_transpose = weights.T\n",
    "\n",
    "one_image_predication = (one_image * weights_transpose).sum() + bias\n",
    "one_image_predication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `T` in `weights.T` stands for **transpose**. It’s a mathematical operation that flips the dimensions of a tensor or matrix. Let’s break this down step by step to explain what it does and why it’s used here.\n",
    "\n",
    "#### 1. **What Does `weights.T` Do?**\n",
    "\n",
    "- If `weights` is a matrix (or tensor), `.T` transposes it:\n",
    "  - Rows become columns, and columns become rows.\n",
    "  - For example:\n",
    "    ```python\n",
    "    weights = [[1, 2],\n",
    "               [3, 4]]\n",
    "    weights.T  # Result: [[1, 3],\n",
    "               #          [2, 4]]\n",
    "    ```\n",
    "\n",
    "- In PyTorch, `.T` is shorthand for `.transpose(0, 1)` (swapping the first and second dimensions).\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Why Use `weights.T` Here?**\n",
    "\n",
    "In the expression `(train_x[0] * weights.T).sum() + bias`, the transpose ensures that the dimensions of `weights` align correctly with `train_x[0]` for matrix multiplication.\n",
    "\n",
    "#### Dimensions Breakdown:\n",
    "- `train_x[0]`: A single data point (e.g., an image flattened into a vector). Shape: `(784,)` (1D tensor with 784 features).\n",
    "- `weights`: The learnable parameters for the model. Shape: `(784, 1)` (2D tensor with 784 rows and 1 column).\n",
    "\n",
    "If you directly multiply `train_x[0]` (shape `(784,)`) with `weights` (shape `(784, 1)`), the dimensions won’t align properly for element-wise multiplication or dot product.\n",
    "\n",
    "By using `weights.T`, the shape becomes `(1, 784)`, which allows the computation to proceed correctly.\n",
    "\n",
    "1. **`train_x[0]`**:\n",
    "   - A single data point (flattened image). Shape: `(784,)`.\n",
    "\n",
    "2. **`weights.T`**:\n",
    "   - Transposed weights. Shape: `(1, 784)`.\n",
    "\n",
    "3. **`train_x[0] * weights.T`**:\n",
    "   - Element-wise multiplication between `train_x[0]` and `weights.T`.\n",
    "   - This computes the weighted contribution of each feature.\n",
    "\n",
    "4. **`.sum()`**:\n",
    "   - Sums up all the weighted contributions to produce a single scalar value.\n",
    "\n",
    "5. **`+ bias`**:\n",
    "   - Adds the bias term to shift the result.\n",
    "\n",
    "The final output is the prediction for the input `train_x[0]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above example was just for one image in our dataset, now how do we do this for all the images to get prediction score? You might be thinking, we will loop through all the dataset and apply the function.\n",
    "We could! However, that would be very slow. Because Python loops don't run on the GPU, and because Python is a slow language for loops in general, we need to represent as much of the computation in a model as possible using higher-level functions.\n",
    "\n",
    "In this case, there's an extremely convenient mathematical operation that calculates `w*x` for every row of a matrix—it's called *matrix multiplication*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, matrix multiplication is represented with the `@` operator. Let's try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20.2336],\n",
       "        [17.0644],\n",
       "        [15.2384],\n",
       "        ...,\n",
       "        [18.3804],\n",
       "        [23.8567],\n",
       "        [28.6816]], grad_fn=<AddBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def linear1(xb): return xb@weights + bias\n",
    "preds = linear1(train_x)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If you are having hard time understanding what just happened here, read the simpler illustration below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional Read:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, let’s assume the image has only 4 pixels instead of 784 (this makes it easier to visualize).\n",
    "```python\n",
    "one_image = [0.1, 0.5, 0.3, 0.9]  # Pixel values of the image (scaled between 0 and 1).\n",
    "\n",
    "#The weights represent how important each pixel is for making a prediction.\n",
    "# Since the input has 4 pixels, the weights will also have 4 values (one for each pixel).\n",
    "weights = [[0.2],  # Weight for pixel 1\n",
    "           [0.4],  # Weight for pixel 2\n",
    "           [-0.1], # Weight for pixel 3\n",
    "           [0.3]]  # Weight for pixel 4\n",
    "\n",
    "#To align the dimensions for element-wise multiplication, we transpose the weights.\n",
    "# Transposing converts weights from shape (4, 1) to (1, 4).\n",
    "weights_transpose = [[0.2, 0.4, -0.1, 0.3]]  # Shape: (1, 4)\n",
    "\n",
    "# Multiply each pixel value in one_image by the corresponding weight in weights_transpose.\n",
    "element_wise_product = [0.1 * 0.2,  # Pixel 1 × Weight 1\n",
    "                        0.5 * 0.4,  # Pixel 2 × Weight 2\n",
    "                        0.3 * -0.1, # Pixel 3 × Weight 3\n",
    "                        0.9 * 0.3]  # Pixel 4 × Weight 4\n",
    "\n",
    "# Result\n",
    "element_wise_product = [0.02, 0.2, -0.03, 0.27]\n",
    "\n",
    "# Add up all the values in the element_wise_product to get a single scalar value.\n",
    "weighted_sum = 0.02 + 0.2 + (-0.03) + 0.27 = 0.46\n",
    "\n",
    "# The bias is a single number that shifts the result up or down.\n",
    "bias = 0.1\n",
    "prediction = weighted_sum + bias = 0.46 + 0.1 = 0.56\n",
    "\n",
    "# Final Prediction\n",
    "one_image_prediction = 0.56\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Side Note: batch @ weights + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This equation, `batch@weights + bias`, is one of the two fundamental equations of any neural network. The second one is **Activation Function**.\n",
    "This expression represents a **linear transformation** commonly used in machine learning, especially in neural networks. Here's what each part means:\n",
    "\n",
    "1. **`batch`**:\n",
    "   - This is a **matrix** (or tensor) containing multiple input data points. Each row corresponds to one data point, and each column corresponds to a feature (e.g., pixel values, sensor readings, etc.).\n",
    "   - Shape: Typically `(n, m)`, where:\n",
    "     - `n` = number of data points in the batch,\n",
    "     - `m` = number of features per data point.\n",
    "\n",
    "2. **`weights`**:\n",
    "   - This is a **matrix** of learnable parameters that the model uses to transform the input data.\n",
    "   - Shape: Typically `(m, p)`, where:\n",
    "     - `m` = number of input features (must match the second dimension of `batch`),\n",
    "     - `p` = number of output features (e.g., neurons in the next layer).\n",
    "\n",
    "3. **`@`**:\n",
    "   - The `@` operator performs **matrix multiplication** between `batch` and `weights`.\n",
    "   - Resulting shape: `(n, p)` (number of data points × number of output features).\n",
    "\n",
    "4. **`bias`**:\n",
    "   - This is a **vector** (or 1D tensor) of learnable parameters added to the result of the matrix multiplication.\n",
    "   - Shape: `(p,)` (must match the number of output features).\n",
    "\n",
    "5. **`+ bias`**:\n",
    "   - After the matrix multiplication, the `bias` is added element-wise to each row of the resulting matrix.\n",
    "\n",
    "### Why Is This Important?\n",
    "\n",
    "The operation `batch @ weights + bias` is the core of a **linear layer** in neural networks. It transforms the input data into a new representation by applying a weighted sum of the inputs and adding a bias term. This transformation is fundamental for tasks like classification, regression, and more.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Calculation Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = [[1, 2, 3],    # Data point 1\n",
    "        [4, 5, 6]]    # Data point 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Shape: `(2, 3)` (2 data points, 3 features).\n",
    "\n",
    "- A **weights** matrix that maps 3 input features to 2 output features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [[0.1, 0.2],  # Weights for output feature 1\n",
    "            [0.3, 0.4],  # Weights for output feature 2\n",
    "            [0.5, 0.6]]  # Weights for output feature 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Shape: `(3, 2)` (3 input features, 2 output features).\n",
    "\n",
    "- A **bias** vector for the 2 output features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = [0.1, 0.2]  # Bias for output feature 1 and 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape: `(2,)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Define the Inputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    ">**Side note:** A feature is like a descriptive attribute or dimension of your data. For example: If we're working with images, features could be pixel values.\n",
    "\n",
    "Let’s say we have:\n",
    "- A **batch** of 2 data points, each with 3 features:\n",
    "  ```python\n",
    "  batch = [[1, 2, 3],    # Data point 1\n",
    "           [4, 5, 6]]    # Data point 2\n",
    "  ```\n",
    "  Shape: `(2, 3)` (2 data points, 3 features).\n",
    "\n",
    "- A **weights** matrix that maps 3 input features to 2 output features:\n",
    "  ```python\n",
    "  weights = [[0.1, 0.2],  # Weights for output feature 1\n",
    "             [0.3, 0.4],  # Weights for output feature 2\n",
    "             [0.5, 0.6]]  # Weights for output feature 3\n",
    "  ```\n",
    "  Shape: `(3, 2)` (3 input features, 2 output features).\n",
    "\n",
    "- A **bias** vector for the 2 output features:\n",
    "  ```python\n",
    "  bias = [0.1, 0.2]  # Bias for output feature 1 and 2\n",
    "  ```\n",
    "  Shape: `(2,)`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Step 2: Perform Matrix Multiplication (`batch @ weights`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the matrix multiplication between `batch` and `weights`. For each data point, this calculates a weighted sum of the input features.\n",
    "\n",
    "Mathematically:\n",
    "$$\n",
    "\\text{result}[i, j] = \\sum_{k} \\text{batch}[i, k] \\cdot \\text{weights}[k, j]\n",
    "$$\n",
    "\n",
    "For our example:\n",
    "```python\n",
    "result = batch @ weights\n",
    "```\n",
    "\n",
    "Step-by-step:\n",
    "1. First data point (`[1, 2, 3]`) multiplied by `weights`:\n",
    "   $$\n",
    "   [1 \\cdot 0.1 + 2 \\cdot 0.3 + 3 \\cdot 0.5, \\quad 1 \\cdot 0.2 + 2 \\cdot 0.4 + 3 \\cdot 0.6]\n",
    "   = [2.2, 2.8]\n",
    "   $$\n",
    "\n",
    "2. Second data point (`[4, 5, 6]`) multiplied by `weights`:\n",
    "   $$\n",
    "   [4 \\cdot 0.1 + 5 \\cdot 0.3 + 6 \\cdot 0.5, \\quad 4 \\cdot 0.2 + 5 \\cdot 0.4 + 6 \\cdot 0.6]\n",
    "   = [4.9, 6.4]\n",
    "   $$\n",
    "\n",
    "So, the result of `batch @ weights` is:\n",
    "```python\n",
    "[[2.2, 2.8],  # Output for data point 1\n",
    " [4.9, 6.4]]  # Output for data point 2\n",
    "```\n",
    "Shape: `(2, 2)`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Step 3: Add the Bias (`+ bias`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we add the `bias` vector `[0.1, 0.2]` to each row of the result.\n",
    "\n",
    "Mathematically:\n",
    "$$\n",
    "\\text{final}[i, j] = \\text{result}[i, j] + \\text{bias}[j]\n",
    "$$\n",
    "\n",
    "For our example:\n",
    "```python\n",
    "final = result + bias\n",
    "```\n",
    "\n",
    "Step-by-step:\n",
    "1. Add bias to the first row:\n",
    "   $$\n",
    "   [2.2 + 0.1, \\quad 2.8 + 0.2] = [2.3, 3.0]\n",
    "   $$\n",
    "\n",
    "2. Add bias to the second row:\n",
    "   $$\n",
    "   [4.9 + 0.1, \\quad 6.4 + 0.2] = [5.0, 6.6]\n",
    "   $$\n",
    "\n",
    "So, the final result is:\n",
    "```python\n",
    "[[2.3, 3.0],  # Final output for data point 1\n",
    " [5.0, 6.6]]  # Final output for data point 2\n",
    " ```\n",
    "\n",
    " Shape: `(2, 2)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The operation `batch @ weights + bias` transforms the input data into a new representation by applying a weighted sum and adding a bias. For our example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "\n",
    "batch = [[1, 2, 3],\n",
    "         [4, 5, 6]]\n",
    "weights = [[0.1, 0.2],\n",
    "           [0.3, 0.4],\n",
    "           [0.5, 0.6]]\n",
    "bias = [0.1, 0.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Side Note: What Is a `Dataset` in PyTorch?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch, a `Dataset` is a class that helps you manage your data. It provides a way to:\n",
    "1. Store your input data (`x`) and labels (`y`).\n",
    "2. Access individual data points (e.g., one image and its label) when needed.\n",
    "\n",
    "When you’re training a machine learning model, you typically use a `Dataset` to feed data into the model in small batches.\n",
    "\n",
    "### What Does \"Return a Tuple of `(x, y)`\" Mean?\n",
    "\n",
    "A `Dataset` in PyTorch is required to return two things for each data point:\n",
    "- `x`: The input data (e.g., an image or feature vector).\n",
    "- `y`: The corresponding label (e.g., the category or target value).\n",
    "\n",
    "These are returned as a **tuple** `(x, y)`.\n",
    "\n",
    "For example:\n",
    "- If you have an image of a handwritten digit `3`, then:\n",
    "  - `x` might be the pixel values of the image.\n",
    "  - `y` might be the label `1` (indicating it’s a `3`).\n",
    "\n",
    "### What Does \"When Indexed\" Mean?\n",
    "\n",
    "The phrase **\"when indexed\"** refers to how you access individual elements from the `Dataset`. In Python, indexing means accessing an element by its position using square brackets (`[]`).\n",
    "\n",
    "For example:\n",
    "```python\n",
    "dataset[0]  # Access the first element in the dataset\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "In PyTorch, when you index a `Dataset` (e.g., `dataset[0]`), it must return a tuple `(x, y)` containing:\n",
    "- `x`: The input data for that specific index.\n",
    "- `y`: The corresponding label for that specific index.\n",
    "\n",
    "### Example: How Indexing Works in a Dataset\n",
    "\n",
    "Let’s say we have a simple `Dataset` with three images and their labels:\n",
    "\n",
    "| Index | Image (`x`)       | Label (`y`) |\n",
    "|-------|-------------------|-------------|\n",
    "| 0     | Image of a `3`    | 1           |\n",
    "| 1     | Image of a `7`    | 0           |\n",
    "| 2     | Image of another `3` | 1       |\n",
    "\n",
    "If you index this dataset:\n",
    "```python\n",
    "dataset[0]  # Returns (image_of_3, 1)\n",
    "dataset[1]  # Returns (image_of_7, 0)\n",
    "dataset[2]  # Returns (another_image_of_3, 1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each time you index the dataset, it gives you a tuple `(x, y)` for the corresponding data point.\n",
    "\n",
    "### Why Is This Important?\n",
    "\n",
    "When training a model, PyTorch uses a `DataLoader` to iterate over the dataset in batches. The `DataLoader` relies on the fact that the `Dataset` returns `(x, y)` when indexed. This ensures that:\n",
    "1. The input data (`x`) and labels (`y`) are paired correctly.\n",
    "2. The data can be fed into the model for training or evaluation.\n",
    "\n",
    "In short: **\"When indexed\" means accessing a specific data point, and the `Dataset` must return the input data and its label as a tuple `(x, y)`.** 😊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 0, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = torch.tensor([[1.,2.,3.], [4.,5.,6.]])\n",
    "b = torch.tensor([[74.,7.,8.], [9.,19.,22.]])\n",
    "cat = torch.cat((a,b))\n",
    "cat.view(-1, 2*3)\n",
    "\n",
    "train_y = torch.tensor([1]*len(a) + [0]*len(b)).unsqueeze(1)\n",
    "train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSTM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
